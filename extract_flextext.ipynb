{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Data from flextext XML files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET # parses XML files\n",
    "import string\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables, Generic Tags/Morphemes, and Other Codes\n",
    "GLOBAL variables that match flextext XML attributes and other information required for consistent handling of the IGT data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# placeholder for unannotated tiers\n",
    "TEMP = '@UNK@'\n",
    "\n",
    "# Generic glosses & POS tags for tokens usually left unannotated\n",
    "PROPER_NOUN = 'nprop'\n",
    "DIGIT = 'num'\n",
    "\n",
    "### FLEXTEXT ATTRIBUTES\n",
    "# flextext XML text/discourse attributes\n",
    "TITLE_TYPE = 'title'\n",
    "COMMENT_TYPE = 'comment'\n",
    "# flextext XML attributes for languages/scripts used in title or translations\n",
    "ENGLISH = 'en'\n",
    "INDONESIAN = 'id'\n",
    "\n",
    "# flextext XML IGT tier attributes\n",
    "TXT = 'txt' # surface morph/segment AND transcribed text\n",
    "CAN_MORPHEME = 'cf' # canonical (underlying) morpheme\n",
    "GLOSS = 'gls' # morpheme gloss AND sentence free translation\n",
    "M_POS = 'msa' # morpheme-level pos = what POS the affix attaches to\n",
    "WORD_POS = 'pos' # word-level pos\n",
    "WORD_GLOSS = 'gls' # word level gloss\n",
    "PUNCT = 'punct' # punctuation\n",
    "\n",
    "# flextext XML morpheme attributes\n",
    "MWE = 'phrase' # multiword expression\n",
    "PREFIX = 'prefix'\n",
    "SUFFIX = 'suffix'\n",
    "CIRCUMFIX = 'circumfix'\n",
    "INFIXES = ['infix', 'infixing interfix']\n",
    "PROCLITIC = 'proclitic'\n",
    "ENCLITICS = ['enclitic', 'clitic'] # Enclitics labed as 'clitic' in some FLEx databases (e.g. lmk)\n",
    "COMPOUND2 = 'bound root B' # Treat second root in compound word as suffix when delimiter markers are needed\n",
    "STEM = 'stem'\n",
    "# all morpheme types\n",
    "STEMS = {'stem', 'bound stem', 'bound root', 'bound root A', 'root', 'particle', 'root'}\n",
    "AFFIXES = [[MWE, PREFIX, SUFFIX, CIRCUMFIX, PROCLITIC], ENCLITICS, INFIXES]\n",
    "\n",
    "### Segment boundaries markers used in flextext XML\n",
    "# Affix types boundaries are marked uniquely in FLEx.\n",
    "# NOTE: Each FLEx database may handle circumfixes boundaries differently.\n",
    "# NOTE: these symbols will need to be removed before re-importing to FLEx.\n",
    "CIRCUM_PRE = '>'\n",
    "CIRCUM_POST = '<'\n",
    "CIRCUM_HOLE = '<>'\n",
    "CLITIC = '='\n",
    "BOUNDROOT = '*'\n",
    "\n",
    "### Keys for output dictionary/JSON\n",
    "TITLE = 'text_title'\n",
    "COMMENT = 'text_comment'\n",
    "SEGNUM = 'line#'\n",
    "FT = 'free_transl'\n",
    "ORIG_LINE = 'orig_line'\n",
    "WORDS = 'words'\n",
    "TOKEN = 'token'\n",
    "POS = 'wPOS'\n",
    "WGLOSS = 'word_gloss'\n",
    "MORPHEMES = 'morphemes'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Metadata for Each Text\n",
    "These functions get metadata associated with each text/discourse such as title and comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTitleComment(xmlsection):\n",
    "    '''find title and comment if in this section\n",
    "    some documents have both and english and native language titles\n",
    "    these checks assure that the both will always be used if found separated by //\n",
    "    if only one of them is found then it is used\n",
    "    if none are found return NO TITLE FOUND'''\n",
    "    \n",
    "    title = \"NO TITLE FOUND\" \n",
    "    eng_title = TEMP\n",
    "    non_eng_title = TEMP\n",
    "    comment = \"No comment\"\n",
    "    \n",
    "    for item_lin in xmlsection.iter('item'):\n",
    "        if item_lin.get('type') == TITLE_TYPE and item_lin.get('lang') == ENGLISH:\n",
    "            eng_title = item_lin.text\n",
    "        if item_lin.get('type') == TITLE_TYPE and item_lin.get('lang') != ENGLISH:\n",
    "            non_eng_title = item_lin.text\n",
    "        if item_lin.get('type') == COMMENT_TYPE and item_lin.get('lang') == ENGLISH:\n",
    "            comment = item_lin.text\n",
    "    # check languages of title and add either or both\n",
    "    if eng_title != TEMP and non_eng_title == TEMP:\n",
    "        title = eng_title \n",
    "    elif eng_title == TEMP and non_eng_title != TEMP:\n",
    "        title = non_eng_title\n",
    "    elif eng_title != TEMP and non_eng_title != TEMP:\n",
    "        title = eng_title + ' // ' + non_eng_title \n",
    "        \n",
    "    return title, comment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing for Consistent and Simplified Data\n",
    "These functions can handle pecularities of a particular corpus and non-conventional IGT annotations. Some may be dispreferred for your purposes and can be edited or commented out, e.g. should bound roots be treated as other roots/stems? \n",
    "\n",
    "Most of this preprocessing must be reversed before re-importing to FLEx. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanWord(IGTstring):  \n",
    "    '''Handle unconventional or confusing use of punctuation in words'''\n",
    "    \n",
    "    IGTstring = str(IGTstring)\n",
    "    \n",
    "    # phrasal lexemes delimited by double tilde\n",
    "    # IGTstring = IGTstring.strip().replace(' ', '~~')\n",
    "    # Strip hyphens from words - hyphens used as Cyrillic quotation mark \n",
    "    IGTstring = IGTstring.strip('-')\n",
    "    # Use tilde in hyphenated words to avoid confusing morpheme delimiter,\n",
    "    # because not all linguists segment hyphenated words on morpheme tier\n",
    "    IGTstring = IGTstring.replace('-', '~')\n",
    "    \n",
    "    return IGTstring.strip().lower()\n",
    "    \n",
    "    \n",
    "def cleanMorph(IGTstring):\n",
    "    '''Handle inconsistent or unconventional annotations in morpheme tiers\n",
    "    (e.g. includes infixes and circumfix halves)'''\n",
    "    \n",
    "    # Replace spaces with period\n",
    "    IGTstring = IGTstring.replace(' ', '.')\n",
    "    # Make morphemes tiers are case insensitive \n",
    "    IGTstring = IGTstring.lower()\n",
    "    # Null morpheme symbol should be consistent across databases, avoid encoding issues\n",
    "    # Add unique null morpheme symbol below\n",
    "    IGTstring = IGTstring.replace('Ø','NULL').replace('∅', 'NULL').replace('zero', 'NULL')\n",
    "    IGTstring = IGTstring.replace('∅', 'NULL')\n",
    "    IGTstring = IGTstring.replace('zero', 'NULL')\n",
    "    IGTstring = IGTstring.replace('*0','NULL') # Lezgi [lez] \n",
    "    \n",
    "    ##OPTIONAL, un/comment as needed\n",
    "    # Remove * on bound roots, to treat as regular stem/root\n",
    "    IGTstring = IGTstring.replace(BOUNDROOT, '-') # ntu\n",
    "        \n",
    "    return IGTstring.strip()\n",
    "\n",
    "\n",
    "def cleanGloss(IGTstring, morpheme_type):\n",
    "    '''Handles inconsistent or unconventional glosses.\n",
    "    Follows Leipzig glossing rules where possible'''\n",
    "    \n",
    "    # Delimit multiple senses in glosses with '.''\n",
    "    IGTstring = IGTstring.replace('-','.')\n",
    "    IGTstring = IGTstring.replace(' ', '.')\n",
    "    # Affix glosses should be in CAPS\n",
    "    if morpheme_type not in STEMS:\n",
    "        IGTstring = IGTstring.upper()\n",
    "    \n",
    "    return IGTstring.strip()\n",
    "\n",
    "\n",
    "def cleanWGloss(IGTstring):\n",
    "    '''Handle inconsistencies and unconventional word level glosses'''\n",
    "    \n",
    "    # Strip hyphens from word glosses. This handles hyphen as Cyrillic quotation mark \n",
    "    IGTstring = IGTstring.strip('-')\n",
    "    # Use tilde in hyphenated words to avoid confusing with morpheme delimiter\n",
    "    IGTstring = IGTstring.replace('-', '~')\n",
    "    \n",
    "    return IGTstring.strip()\n",
    "\n",
    "\n",
    "def cleanPOS(IGTstring):\n",
    "    '''Handles inconsistencies and unconventional morpheme-level and word-level POS'''\n",
    "    \n",
    "    ### OPTIONAL: add other pre-processing specific to a database\n",
    "    IGTstring = IGTstring.replace('N (kx cl)', 'N(kx.cl)') # Natugu [ntu] morpheme pos\n",
    "    \n",
    "    ## Delimit multiple tags per token with '.'\n",
    "    IGTstring = IGTstring.replace(' ', '.')\n",
    "    # Remove FLEx-inserted hyphens, to avoid confusing with morpheme delimiter\n",
    "    IGTstring = IGTstring.replace('pro-form', 'proform')\n",
    "    IGTstring = IGTstring.replace('Nom-1','Nom1')\n",
    "    \n",
    "    return IGTstring.strip()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Interlinear Tiers Annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Morpheme Tier Annotations\n",
    "This includes surface morph, morpheme, morpheme type and boundary delimiters, morpheme \"POS\" (category of attachment), etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getInfixedStem(wordtxt, morphitem, infix):\n",
    "    '''Infixed stems need special processing,\n",
    "    especially for NLP models that require one gloss per morpheme'''\n",
    "    \n",
    "    # NOTE: FLEx seems to always put infix before its stem\n",
    "    # THIS CODE CUT FROM MAIN EXTRACTION FUNCTION. \n",
    "    # In future may need to handle inflectional infixes \n",
    "    # instead treating as part of stem\n",
    "    # because all my databases so far only have derivationl infixes, and few very of them\n",
    "                                #preinfix, postinfix = getInfixedStem(str(wrd), morph, temp_word[-1])\n",
    "                                # insert first half of prefix for surface segmentation\n",
    "                                #infix_index = len(affix_order)-2\n",
    "                                #temp_word.insert(infix_index-1, preinfix)\n",
    "                                # add second half of infixed stem\n",
    "                                #temp_morph = postinfix\n",
    "    \n",
    "    pre_temp_morph = [TEMP, TEMP, TEMP, TEMP]\n",
    "    post_temp_morph = [TEMP, TEMP, TEMP, TEMP]\n",
    "    \n",
    "    infix = infix[0][1:-1] # remove dashes surrounding infixes\n",
    "    stemhalves = wordtxt.split(infix) # treat strings surrounding infixes as stems\n",
    "    \n",
    "    # get other tiers\n",
    "    for item in morphitem.iter('item'):\n",
    "        if item.get('type') != None or item.text != '' or item.text != '<NotSure>' or item.text != ' ':\n",
    "            # get surface morph, treat same as stem halves\n",
    "            if (item.get('type') == TXT):\n",
    "                pre_temp_morph[0] = cleanGloss(stemhalves[0])\n",
    "                post_temp_morph[0] = cleanGloss(stemhalves[1])\n",
    "            # canonical morpheme, will be nothing for first half if infixed\n",
    "            elif(item.get('type') == CAN_MORPHEME):\n",
    "                pre_temp_morph[1] = cleanMorph(item.text)\n",
    "                post_temp_morph[1] = cleanMorph(item.text)\n",
    "            # gloss, same for both\n",
    "            elif(item.get('type') == GLOSS):\n",
    "                # separate multi-word glosses with \".\"\n",
    "                pre_temp_morph[2] = cleanGloss(item.text)\n",
    "                post_temp_morph[2] = cleanGloss(item.text)\n",
    "            # morpheme pos\n",
    "            elif(item.get('type') == M_POS):\n",
    "                pre_temp_morph[3] = cleanPOS(item.text)\n",
    "                post_temp_morph[3] = cleanPOS(item.text)\n",
    "        else:\n",
    "            continue\n",
    "    \n",
    "    return pre_temp_morph, post_temp_morph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generalizeMorphemeType(morphemetype):\n",
    "    '''Reduces number of morpheme types allowed in FLEx'''\n",
    "    \n",
    "    unknown_morphemetype = True\n",
    "    \n",
    "    ## Stems: Use same tag for all stem-like morphemes\n",
    "    # Assume missing morpheme type attribute indicates stem\n",
    "    if morphemetype == None or morphemetype in STEMS:\n",
    "        morphemetype = STEM  \n",
    "        unknown_morphemetype = False\n",
    "    # Treat 2nd half of compound word (bound root B) as suffix to keep boundary marker\n",
    "    elif morphemetype == COMPOUND2:\n",
    "        morphemetype = SUFFIX\n",
    "        unknown_morphemetype = False\n",
    "        \n",
    "    ## Catch any morpheme types not handled yet\n",
    "    elif unknown_morphemetype:\n",
    "        for affixtype in AFFIXES:\n",
    "            if morphemetype in affixtype:\n",
    "                unknown_morphemetype = False\n",
    "                break\n",
    "    if unknown_morphemetype:\n",
    "        print(\"\\nThis morpheme type XML attribute is not handled yet in getMorpheme(): \" + morphemetype)\n",
    "    \n",
    "    return morphemetype\n",
    "\n",
    "\n",
    "def affixDelimiter(morphemetype, morphemetext):\n",
    "    '''Add delimiter indicating affix type'''\n",
    "    \n",
    "    if morphemetype in ENCLITICS:\n",
    "        return CLITIC + cleanMorph(morphemetext)\n",
    "    elif morphemetype == PROCLITIC:\n",
    "        return cleanMorph(morphemetext) + CLITIC\n",
    "    else:\n",
    "        return cleanMorph(morphemetext)\n",
    "\n",
    "    \n",
    "def circumfixDelimiter(morphemetype, morphemetext, numaffix):\n",
    "    '''FLEx handles circumfixes differently.\n",
    "    This makes that consistent at canonical morpheme level.\n",
    "    TODO?: do not assume only 1 circumfix per word'''\n",
    "    \n",
    "    if morphemetype == CIRCUMFIX:\n",
    "        # if first half of circumfix is word-initial, treat as prefix\n",
    "        if len(numaffix) == 1:\n",
    "            return cleanMorph(morphemetext) + CIRCUM_PRE\n",
    "        # if first half of circumfix is not word-initial, treat as infix\n",
    "        else:\n",
    "            return CIRCUM_POST + cleanMorph(morphemetext) + CIRCUM_PRE\n",
    "    \n",
    "    # Treat second circumfix half as suffix and circumfixed stem as stem\n",
    "    elif '-...-' in morphemetext:\n",
    "        if morphemetype in STEMS or morphemetype == MWE:\n",
    "            return cleanMorph(item.text).replace('-...-', '')\n",
    "        elif morphemetype == PREFIX:\n",
    "            return cleanMorph(morphemetext).replace('-...-', CIRCUM_PRE)\n",
    "        elif morphemetype == SUFFIX:\n",
    "            return CIRCUM_POST + cleanMorph(morphemetext).replace('-...-', '')\n",
    "\n",
    "         \n",
    "def getMorpheme(morphsubitems, morphemetype, numaffix):\n",
    "    '''OUTPUT for each morpheme: [morph, morpheme, gloss, mpos, morphemetype]\n",
    "    \n",
    "    To add more tiers annotations to this array:\n",
    "    1st. Add another holding place in the morph_info array with TEMP variable\n",
    "    2nd. Give index for new tier annotation.\n",
    "    3rd. Add elif statement for new tier using the attribute needed, e.g. 'morpheme type'.\n",
    "        If necessary, create special delimiter and add/edit a \"preprocessing/cleaning\" function above.\n",
    "    4th. Check that that morph_info array matches entries in temp_morph\n",
    "        and does not mess up with punctuation processing, etc.'''\n",
    "    \n",
    "    # 1st. temporary array for morpheme information\n",
    "    morph_info = [TEMP, TEMP, TEMP, TEMP, generalizeMorphemeType(morphemetype)]\n",
    "    \n",
    "    # 2nd. indexes for types of information to be in morph_info\n",
    "    MORPH_IDX = 0\n",
    "    MORPHEME_IDX = 1\n",
    "    GLOSS_IDX = 2\n",
    "    M_POS_IDX = 3\n",
    "    TYPE_IDX = 4\n",
    "    \n",
    "    # 3rd. extract IGT tier annotations for morpheme\n",
    "    for item in morphsubitems.iter('item'):\n",
    "        if item.text != None:\n",
    "            # TIER => surface morph (txt)\n",
    "            if (item.get('type') == TXT):\n",
    "                morph_info[MORPH_IDX] = affixDelimiter(morphemetype, item.text)\n",
    "\n",
    "            # TIER => canonical morpheme (cf)\n",
    "            elif(item.get('type') == CAN_MORPHEME):\n",
    "                if morphemetype == CIRCUMFIX or '-...-' in item.text: \n",
    "                    morph_info[MORPHEME_IDX] = circumfixDelimiter(morphemetype, item.text, numaffix)\n",
    "                else:\n",
    "                    morph_info[MORPH_IDX] = affixDelimiter(morphemetype, item.text)\n",
    "                    \n",
    "            # TIER => morpheme gloss\n",
    "            elif (item.get('type') == GLOSS):\n",
    "                morph_info[GLOSS_IDX] = cleanGloss(item.text, morphemetype)\n",
    "            \n",
    "            # TIER: morpheme pos\n",
    "            elif(item.get('type') == M_POS):\n",
    "                morph_info[M_POS_IDX] = cleanPOS(item.text)\n",
    "                           \n",
    "    return morph_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Level Tier Annotations\n",
    "This includes word level POS tag, word gloss, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genericPOS(current_token, current_token_type):\n",
    "    '''Add missing POS tag for digit, punct'''\n",
    "    \n",
    "    if current_token.isdigit():\n",
    "        return DIGIT\n",
    "    \n",
    "    if current_token_type == PUNCT or current_token == '~':\n",
    "        return PUNCT.upper()\n",
    "    \n",
    "    return TEMP\n",
    "\n",
    "\n",
    "def getWPOS(current_tokenXML, current_token, current_token_type):\n",
    "    '''Extract word level POS tags'''\n",
    "    \n",
    "    temp_wpos = TEMP\n",
    "    for word_item in current_tokenXML.iter('item'):\n",
    "        if word_item.get('type') == WORD_POS:\n",
    "            temp_wpos = cleanPOS(word_item.text)\n",
    "    \n",
    "    if temp_wpos == TEMP:\n",
    "        temp_wpos = genericPOS(current_token, current_token_type)\n",
    "    \n",
    "    return temp_wpos\n",
    "\n",
    "\n",
    "def getWordGloss(current_tokenXML, current_token, current_token_type):\n",
    "    '''Extract word level gloss if present. \n",
    "    Currently ASSUMES ONLY TWO WORD GLOSS LANGS and ENG IS always 1st.\n",
    "    TODO: Find a way not to depend on index of word level XML nodes'''\n",
    "    \n",
    "    word_gloss = TEMP\n",
    "    # Can't iterate on only one level easily with ETree, so use index of word level XML nodes\n",
    "    if len(current_tokenXML) < 4:\n",
    "        # If punctuation gloss missing, copy from original text\n",
    "        if current_tokenXML[0].get('type') == PUNCT:\n",
    "            word_gloss = PUNCT\n",
    "    elif current_tokenXML[-2].get('type') == WORD_GLOSS and current_tokenXML[-2].get('lang') == 'en':\n",
    "        if current_tokenXML[-2].text != None:\n",
    "            word_gloss = cleanWGloss(current_tokenXML[-2].text)\n",
    "    \n",
    "    # Choose English gloss.\n",
    "    elif current_tokenXML[-3].get('type') == WORD_GLOSS and current_tokenXML[-3].get('lang') == 'en':\n",
    "         if current_tokenXML[-3].text != None:\n",
    "            word_gloss = cleanWGloss(current_tokenXML[-3].text)\n",
    "    \n",
    "    return word_gloss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Line/Sentence/Phrase Tier Annotations\n",
    "\n",
    "This includes free translations, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFreeTransl(phrase):\n",
    "    '''Get Free translations.\n",
    "    # TODO: handle as many languages if needed'''\n",
    "    \n",
    "    if phrase.find('item').get('type') == GLOSS:\n",
    "        if phrase.find('item').get('lang') == ENGLISH:\n",
    "            return phrase.find('item').text\n",
    "        else:\n",
    "            return phrase.find('item').text\n",
    "    return TEMP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Extraction\n",
    "\n",
    "Words: \n",
    "\n",
    "Current: `[{title, comment, line#, free_transl, origline_w_digits_punct, \"words\":[\n",
    "                {'token': word_txt, 'wPOS':wpostag, 'word_gloss':wgloss, \"morphemes\":[\n",
    "                    [morph, morpheme, gloss, mpos, morphemetype]` \n",
    "                    \n",
    "         e.g. words: [{'token': 'birii', 'wPOS': 'V.ISA.MRK.UV', 'morphemes': [['biri', 'bori', 'give', 'V', 'stem'], ['-i', '-ei', 'ISA.MRK.UV.IMP', 'V.ISA>V.ISA.MRK.UV', 'suffix']], 'word_gloss': 'give'}, {'token': 'ihi', 'wPOS': 'PERS.PRO', 'morphemes': [['ihi', 'ihi', 'kami', 'PERS.PRO', 'stem']], 'word_gloss': 'we'}, {'token': 'egas', 'wPOS': 'N', 'morphemes': [['egas', 'egas', 'beras', 'N', 'root']], 'word_gloss': 'rice'}, {'token': '.', 'wPOS': 'PUNCT', 'morphemes': [['.', '.', '@@@', 'PUNCT', 'punct']], 'word_gloss': 'punct'}]\n",
    "\n",
    "Old: `[{\"text_title\":title, \"text_comment\":comment, \"words\":[\n",
    "            {\"segnum\":line#, \"token\":word, \"POS\":postag, \"morphemes\": [\n",
    "                            [morph, morpheme, gloss, mpos, morphemetype]\n",
    "                         ]}]` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genericGloss(temp_wpos, morphemetype):\n",
    "    '''Add generic gloss to unglossed \n",
    "    proper nouns (stem), punct, and digits.'''\n",
    "    if temp_wpos == PROPER_NOUN and morphemetype in STEMS:\n",
    "        return PROPER_NOUN.upper()\n",
    "    if temp_wpos == DIGIT:\n",
    "        return DIGIT.upper()\n",
    "    elif temp_wpos == PUNCT:\n",
    "        return PUNCT.upper()\n",
    "    return TEMP\n",
    "\n",
    "\n",
    "def genericMorpheme(token_string, morph, temp_wpos, morphemetype):\n",
    "    '''Proper nouns (stem), punct, and digits only:\n",
    "    Copy morph if morpheme missing. \n",
    "    Copy original word string if missing morph.'''\n",
    "    if (temp_wpos == PROPER_NOUN and morphemetype in STEMS) or temp_wpos == DIGIT or temp_wpos == PUNCT:\n",
    "        if morph == TEMP:\n",
    "            return token_string, token_string\n",
    "        else:\n",
    "            return morph, morph\n",
    "    return morph, TEMP\n",
    "\n",
    "\n",
    "#### MAIN EXTRACTION ####\n",
    "def extract_flextext(flextext_filename):\n",
    "    '''Takes FLExText XML any number of texts. OUTPUT list of line dicts: \n",
    "    [{title, comment, line#, free_transl, origline_w_digits_punct, \"words\":[\n",
    "                {word_txt, wpostag, wgloss, \"morphemes\":[\n",
    "                    [morph, morpheme, gloss, mpos, morphemetype]]}]}]'''\n",
    "\n",
    "    root = ET.parse(flextext_filename).getroot()\n",
    "    lines = []\n",
    "    total_lexemes = 0 # Don't count punct or digits. NOTE: MWE is 1 lexeme\n",
    "    total_tokens = 0\n",
    "    pos_tags_in_corpus = set()\n",
    "    \n",
    "    for text in root.iter('interlinear-text'):\n",
    "        title,comment = getTitleComment(text)\n",
    "        # Extract phrase (sentence/line), word, morpheme level, ignore paragraph breaks\n",
    "        for line_idx,phrase in enumerate(text.iter('phrase')):\n",
    "            temp_line = {}\n",
    "            temp_words = []\n",
    "            no_punct_line = ''\n",
    "            orig_line = []\n",
    "\n",
    "            # FLExtext \"segnum\" is ID for phrases\n",
    "            if phrase.find('item').get('type') == 'segnum':\n",
    "                lineid = phrase.find('item').text\n",
    "            else:\n",
    "                lineid = str(line_idx)                \n",
    "            \n",
    "            # Extract free translations\n",
    "            temp_transl = getFreeTransl(phrase)\n",
    "            \n",
    "            # Extract token (word) level info, as tokenized by FLEx user.\n",
    "            # Note: MWE (phrasal lexems) are treated as one \"word\"\n",
    "            for token_idx,token in enumerate(phrase.iter('word')):\n",
    "                tokentype = token.find('item').get('type')\n",
    "                token_string = cleanWord(token.find('item').text)\n",
    "                \n",
    "                if token_string: # Ignore blank strings\n",
    "                    total_tokens+=1\n",
    "                    orig_line.append(token_string)\n",
    "                    temp_morphemes = []\n",
    "                    affix_order = [] # order of affixes to align infixes later         \n",
    "                    \n",
    "                    # Count lexemes\n",
    "                    if tokentype != PUNCT and token_string != '~' and not token_string.isdigit():\n",
    "                        no_punct_line += token_string\n",
    "                        total_lexemes+=1    \n",
    "                    \n",
    "                    # Extract word-level tier annotations\n",
    "                    temp_wgloss = getWordGloss(token, token_string, tokentype)\n",
    "                    temp_wpos = getWPOS(token, token_string, tokentype)\n",
    "                    pos_tags_in_corpus.add(temp_wpos)\n",
    "                    \n",
    "                    # Extract morpheme level tier annotations, if any\n",
    "                    if token.find('morphemes') == None:  \n",
    "                        temp_morphemes.append([token_string, TEMP, TEMP, temp_wpos, tokentype])\n",
    "                    else:\n",
    "                        for morphsubitem in token.iter('morph'):\n",
    "                            morphemetype = morphsubitem.get('type')\n",
    "                            \n",
    "                            # TODO: for non-neural models which need input/output alignment\n",
    "                            # morpheme type will determine what part of string is infix\n",
    "                            affix_order.append(morphemetype)\n",
    "                            \n",
    "                            # TODO: Handle infixes\n",
    "                            #if len(affix_order) >= 2 and affix_order[-2] in infixes:\n",
    "                            #else: \n",
    "                            temp_morph = getMorpheme(morphsubitem, morphemetype, affix_order)\n",
    "                            \n",
    "                            # Create generic gloss and morpheme segments\n",
    "                            if temp_morph[2] == TEMP: \n",
    "                                temp_morph[2] = genericGloss(temp_wpos, morphemetype)\n",
    "                            if temp_morph[1] == TEMP:\n",
    "                                temp_morph[0], temp_morph[1] = genericMorpheme(token_string, temp_morph[0], temp_wpos, morphemetype)\n",
    "                            \n",
    "                            temp_morphemes.append(temp_morph)\n",
    "                    \n",
    "                    temp_words.append({TOKEN:token_string, POS:temp_wpos, MORPHEMES:temp_morphemes, WGLOSS:temp_wgloss})            \n",
    "        \n",
    "            orig_line = ' '.join(orig_line)\n",
    "            temp_line = {TITLE:title, COMMENT:comment, SEGNUM:lineid, FT:temp_transl, ORIG_LINE:orig_line, WORDS:temp_words}\n",
    "            lines.append(temp_line)\n",
    "    \n",
    "    # Print corpus statistics\n",
    "    print(\"Parts of speech found in corpus:\", pos_tags_in_corpus, end='\\n\\n')\n",
    "    print(\"All Tokens:\", total_tokens)\n",
    "    print(\"Lexemes, ignoring punctuation and digits:\", total_lexemes)\n",
    "    # sanity check first line\n",
    "    print('Initial Extraction Sanity Check:', lines[0][WORDS][:10])\n",
    "    print('Extraction done...\\n')\n",
    "                                \n",
    "    return lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post Extraction Filtering \n",
    "\n",
    "Filtering has to happen after extraction because all the preprocessing, \"cleaning\", and adding generic tags and morphemes has to be done first. \n",
    "\n",
    "### Morpheme Filters\n",
    "\n",
    "To filter out words or lines based on morpheme annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def glossed(word_by_morphemes):\n",
    "    '''checks gloss of every morpheme in a word\n",
    "        if missing glosses, flags word as unglossed;\n",
    "        assumes segmentation is complete'''\n",
    "    for segment in word_by_morphemes:\n",
    "        if segment[2] == TEMP:\n",
    "            return False\n",
    "    return True\n",
    "    \n",
    "def surfSegmented(word_by_morphemes):\n",
    "    '''flags words that have not been segmented \n",
    "    (i.e. no <morphemes> tag in XML, or no morph)\n",
    "    should not flag monomorphemic words'''\n",
    "    if len(word_by_morphemes) == 1 and word_by_morphemes[0][0] == TEMP:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def canonSegmented(word_by_morphemes):\n",
    "    '''no words that have not been canonically segmented'''\n",
    "    if len(word_by_morphemes) == 1 and word_by_morphemes[0][1] == TEMP:\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word filters\n",
    "\n",
    "Filter words or lines based on word annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def properNoun(word_postag):\n",
    "    if word_postag == PROPER_NOUN:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def punct(word_postag):\n",
    "    if word_postag == PUNCT:\n",
    "        return True\n",
    "    return False\n",
    "                           \n",
    "def multiword(lexical_item):\n",
    "    '''flag if original text of token has spaces'''\n",
    "    if ' ' in lexical_item or '~' in lexical_item or '-' in lexical_item:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def selected_pos(word_postag):\n",
    "    '''filter a list of specified word level POS'''    \n",
    "    # check word level POS tag\n",
    "    if word_postag not in SELECT_POS_TAGS:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Line Filters\n",
    "\n",
    "Filter lines or texts based on line/sentence/phrase/clause annotations, e.g. free translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hasFreeTrans(ft_line):\n",
    "    '''Checks if has (English) free translation.\n",
    "    TODO: Check by language'''\n",
    "    if ft_line:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COMBINE FILTERING FUNCTIONS HERE AS NEEDED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def filtering(extractedtexts, task, bysentence, useoriginalline):\n",
    "    '''Write custom filter functions above, un/comment calls here\n",
    "        as needed for your purposes to create gold standard dataset.'''\n",
    "    \n",
    "    gold_standard = []\n",
    "    unlabeled = []\n",
    "    punctuation = 0\n",
    "    digits = 0\n",
    "    tokens = 0\n",
    "    # End of sentence marker\n",
    "    EOS = {TOKEN:'EOS', POS:'@EOS@', MORPHEMES:['@EOS@', '@EOS@', '@EOS@', '@EOS@', '@EOS@'], WGLOSS: '@EOS@'}\n",
    "    \n",
    "    for line in extractedtexts:\n",
    "        linewords = [] \n",
    "        linestatus = [] # Check for unannotated items\n",
    "        temp_gold_standard = []\n",
    "        temp_unlabeled = [] \n",
    "        \n",
    "        for word in line[WORDS]:\n",
    "            tokens+=1\n",
    "            good4training = True\n",
    "            \n",
    "            ## Find missing morpheme glosses\n",
    "            if (task == '_gls' or task == '_surSegGls' or task == '_canSegGls') and not glossed(word[MORPHEMES]): good4training = False\n",
    "            \n",
    "            ## Find missing canonical (underlying) segments\n",
    "            if (task == '_canSeg' or task == '_canSegGls') and not canonSegmented(word[MORPHEMES]): good4training = False\n",
    "            \n",
    "            ## Find missing surface segments\n",
    "            if (task == '_surSeg' or task == '_surSegGls') and not surfSegmented(word[MORPHEMES]):  good4training = False\n",
    "            \n",
    "            ## Find missing word POS tags\n",
    "            if (task == '_pos' or task == '_infl') and word[POS] == TEMP: good4training = False\n",
    "            \n",
    "            ## Find missing word gloss\n",
    "            if task == '_wrdgls' and word[WGLOSS] == TEMP: good4training = False\n",
    "            \n",
    "            ### Uncomment lines below to find missing annoations or undesirable tokens ####\n",
    "            ## Filter out MWE\n",
    "            #if multiword(word['token']): good4training = False\n",
    "            \n",
    "            ## Filter out unknown, unselected, or unspecified POS\n",
    "            #if not selected_pos(word[POS]): good4training = False\n",
    "            \n",
    "            ## Filter out digits\n",
    "            #if word[POS] == DIGIT: \n",
    "                #good4training = False\n",
    "                #digits+=1\n",
    "            \n",
    "            ## Filter out punctuation\n",
    "            #if isPunct(word[POS]): \n",
    "                #good4training = False\n",
    "                #punctuation+=1\n",
    "            \n",
    "            ### Split filtered and unfiltered words\n",
    "            if not bysentence:\n",
    "                if good4training:\n",
    "                    temp_gold_standard.append(word)\n",
    "                else:\n",
    "                    temp_unlabeled.append(word)\n",
    "                    \n",
    "            # Create new sentences from unfiltered word/pos\n",
    "            else:\n",
    "                linewords.extend(word)\n",
    "                linestatus.append(good4training)\n",
    "                \n",
    "        ### Combine datasets\n",
    "        # Filter and split sentences\n",
    "        if bysentence:\n",
    "            ## Add end of sentence marker: to recreate sentences after training NLP model by word tokens\n",
    "            #linewords.append(EOS)\n",
    "            if all(linestatus):\n",
    "                if useoriginalline: \n",
    "                    gold_standard.append(line)\n",
    "                else: \n",
    "                    gold_standard.append(linewords)\n",
    "            else:\n",
    "                if useoriginalline: \n",
    "                    unlabeled.append(line)\n",
    "                else: \n",
    "                    unlabeled.append(linewords)\n",
    "\n",
    "        # Filter words\n",
    "        else:\n",
    "            gold_standard.extend(temp_gold_standard)\n",
    "            unlabeled.extend(temp_unlabeled)\n",
    "    \n",
    "    print('Post filtering statistics:')\n",
    "    print(\"\\tTotal words after filtering:\", tokens)\n",
    "    print(\"\\tTotal training examples, after filtering for\", task, len(gold_standard))\n",
    "    print(\"\\tTotal punctuation and digits:\", punctuation+digits, end='\\n\\n')\n",
    "    \n",
    "    return gold_standard, unlabeled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write to Files\n",
    "\n",
    "### Final Checks, Formatting,  and Write to Text Files\n",
    "\n",
    "Doublecheck there's a gloss for every morph(eme) and same number POS tags / word glosses as tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def aligned(a, b):\n",
    "    if len(a) != len(b):\n",
    "        raise ValueError(\"must be same number of morph(emes) and gloss in a word\")\n",
    "        \n",
    "# Prepare sentence level alignments for text files\n",
    "def poslines(listofwords, listofPOStags):\n",
    "    \"Arranges POS by sentences for training\"\n",
    "    stringtags = '%%'.join(listofPOStags)\n",
    "    listofwords = [''.join(word.split()) for word in listofwords]\n",
    "    stringwords = '%%'.join(listofwords)\n",
    "    bysenttags = stringtags.split('@EOS@')\n",
    "    bysentwords = stringwords.split('EOS')\n",
    "    return [' '.join(sent.split('%%')).strip() for sent in bysentwords], [' '.join(sent.split('%%')).strip() for sent in bysenttags]\n",
    "\n",
    "# Prepare sentence level alignments for text files\n",
    "def wrdglsLines(listofwords, listofwordglosses):\n",
    "    \"Arranges word glosses by sentences for training\"\n",
    "    stringtags = '%%'.join(listofwordglosses)\n",
    "    listofwords = [''.join(word.split()) for word in listofwords]\n",
    "    stringwords = '%%'.join(listofwords)\n",
    "    bysenttags = stringtags.split('@EOS@')\n",
    "    bysentwords = stringwords.split('EOS')\n",
    "    return [' '.join(sent.split('%%')).strip() for sent in bysentwords], [' '.join(sent.split('%%')).strip() for sent in bysenttags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataFiles(extracted_words, training_task, outfilepath):\n",
    "    '''Writes two text files: X and y (tokens and annotations; input and output)'''\n",
    "    \n",
    "    input_data = []\n",
    "    output_data = []\n",
    "    \n",
    "    for word in extracted_words: \n",
    "        if training_task != '_gls':\n",
    "            # input string (X)\n",
    "            input_data.append(' '.join(word[TOKEN])) # insert space between chars\n",
    "        \n",
    "        # output types (y)\n",
    "        wPOS_tag = word[POS]\n",
    "        word_gloss = word[WGLOSS]\n",
    "        inflection_gloss = [word[POS]]\n",
    "        canonical_morphemes = []\n",
    "        surface_morphemes = []\n",
    "        glosses = []\n",
    "        for morpheme in word[MORPHEMES]:\n",
    "            surface_morphemes.append(morpheme[0])\n",
    "            canonical_morphemes.append(morpheme[1])\n",
    "            glosses.append(morpheme[2])\n",
    "            if morpheme[-1] != STEM:\n",
    "                inflection_gloss.append(morpheme[2])\n",
    "\n",
    "        # determines what will be written to output file\n",
    "        #TODO: _canSegGls & _canSeg must handle null morphemes for non-neural models (CRF)\n",
    "        if training_task == '_pos':\n",
    "            output_data.append(wPOS_tag)\n",
    "        elif training_task == '_wrdgls':\n",
    "            output_data.append(wordgloss)\n",
    "        elif training_task == '_gls':\n",
    "            input_data.append(' '.join(surface_morphemes)) # input string (X)\n",
    "            output_data.append(' '.join(glosses)) \n",
    "        elif training_task == '_canSeg':\n",
    "            output_data.append(' '.join(canonical_morphemes))\n",
    "        elif training_task == '_surSeg':\n",
    "            output_data.append(' '.join(surface_morphemes))\n",
    "        elif training_task == '_surSegGls':\n",
    "            aligned(surface_morphemes, glosses)\n",
    "            combined_seg_gls = [morph+'#'+glosses[i] for i,morph in enumerate(surface_morphemes)]\n",
    "            output_data.append(' '.join(combined_seg_gls))\n",
    "        elif training_task == '_canSeg':\n",
    "            output_data.append(' '.join(canonical_morphemes))\n",
    "        elif training_task == '_canSegGls':\n",
    "            aligned(canonical_morphemes, glosses)\n",
    "            combined_seg_gls = [morpheme+'#'+glosses[i] for i,morpheme in enumerate(canonical_morphemes)]\n",
    "            output_data.append(' '.join(combined_seg_gls))\n",
    "        elif training_task == '_infl':\n",
    "            output_data.append(' '.join(inflection_gloss))\n",
    "        else:\n",
    "            print(\"Output format not found.\")\n",
    "    \n",
    "    # prepare for sentence level POS tagging and word glossing\n",
    "    if training_task == '_pos':\n",
    "        input_data, output_data = poslines(input_data, output_data)\n",
    "    if training_task == '_wrdgls':\n",
    "        input_data, output_data = wrdglsLines(input_data, output_data)\n",
    "    \n",
    "    # write master data files\n",
    "    with open(outfilepath+training_task+'.input', 'w', encoding='utf8') as I:\n",
    "        I.write('\\n'.join(input_data)[:-1])\n",
    "    with open(outfilepath+training_task+'.output', 'w', encoding='utf8') as O:\n",
    "        O.write('\\n'.join(output_data)[:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dump to Json File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flextext2Json(pathname, gold_standard):\n",
    "    with open(pathname+'.json', 'w') as write_file:\n",
    "        json.dump(gold_standard, write_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "####### EXTRACT from flextext#######\n",
    "def main(tostorepath, dbfile, task, bysentence, useoriginalline, json):\n",
    "    \n",
    "    master_data = extract_flextext(dbfile)\n",
    "\n",
    "    # NOTE: FIRST EDIT filtering() function to suit your task!\n",
    "    gold_standard, unannotated = filtering(master_data, task, bysentence, useoriginalline)\n",
    "    print(\"\\nSanity check training examples:\\n\", gold_standard[-5:])\n",
    "    print(\"\\nSanity check unannotated data:\\n\", unannotated[-5:])\n",
    "    \n",
    "    #### Write files ####\n",
    "    ### Text files, word per line\n",
    "    if not json:\n",
    "        ## write all extracted tokens to _M file \n",
    "        dataFiles(gold_standard+unannotated, task, tostorepath+'_Master')\n",
    "        ## write filtered out tokens to _U(nannotated) file\n",
    "        if unannotated:\n",
    "            dataFiles(unannotated, task, tostorepath+'_U')\n",
    "        ## write remaining tokens to T(raining)/L(abeled) file\n",
    "        dataFiles(gold_standard, task, tostorepath+'_L')\n",
    "    \n",
    "    ### Filtered data only to JSON file\n",
    "    if json:\n",
    "        flextext2Json(tostorepath+task, gold_standard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Run "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "LANGUAGE: bdg\n",
      "Parts of speech found in corpus: {'PEG-tsc.AV.<.V', 'ASP', 'CLF', 'ST.ATTR', 'V.ADVRS.ACH', 'N.ABSTR', 'Prep', 'PEG-tsc.AV.<.N', 'V.PLAC.ACY', 'Adv.loc', 'N.Temp', 'AUX.UV', 'V.ISA.UV', 'REFL.PRO', 'PRT', 'Ord.Num', 'ADNOM.DEM', 'N.p-.-an', 'Adv', 'INDEF.PRO', 'V.ST.PER', 'N.Voc', 'NEG.PRO', 'Subordconj', 'V.ST', 'NEG', 'N', 'V.PET', 'NP', 'CLS.MENS', '@UNK@', 'ADJ', 'peg-verb.temp.sub.cl', 'V.ST1', 'V.ACL', 'V.ISA', 'Conn', 'INTNS', 'N.peg-.-an', 'QUAN', 'PP', 'EX.ST', 'CLS.SORT', 'Det.PN', 'N.Prop', 'Coordconj', 'ADV.MAN', 'PUNCT', 'QW', 'PERS.PRO', 'TNS', 'V.CAUS.UV', 'V.DES.MOD', 'V.ACH', 'PersName', 'MOD', 'Card.Num', 'Rel', 'Adv.temp', 'Det', 'N.DIMIN.redup', 'V.ST.EMO', 'V.CAUS.AV', 'V.CAUS', 'V.ST2', 'V.ST.POSS.denom', 'N.CHAR.NMLZ', 'PEG-tsc.UV.<.V', 'V.ST.COG', 'N.PROD', 'V.ST.DES', 'Adv.pace', 'V.ACY.C2', 'V.ISA.AV', 'MO.ACY.PATH', 'V.ISA.MRK.UV', 'V.ACY.M', 'V.ACY', 'Adv.epis', 'V.ACD.MOD', 'V.ST.POS', 'V.INSTRV', 'INT.EXP.ST', 'V.ST.POSS', 'V.ACH.ABIL', 'Adv.freq', 'V.ACY.SE', 'V', 'MO.ACY.M', 'DEM.PRO', 'V.ABL.MOD', 'Mult.Num', 'COND.ST', 'Interj'}\n",
      "\n",
      "All Tokens: 27543\n",
      "Lexemes, ignoring punctuation and digits: 21616\n",
      "Initial Extraction Sanity Check: [{'token': 'birii', 'wPOS': 'V.ISA.MRK.UV', 'morphemes': [['bori', '@UNK@', 'give', 'V', 'stem'], ['-ei', '@UNK@', 'ISA.MRK.UV.IMP', 'V.ISA>V.ISA.MRK.UV', 'suffix']], 'word_gloss': 'give'}, {'token': 'ihi', 'wPOS': 'PERS.PRO', 'morphemes': [['ihi', '@UNK@', 'kami', 'PERS.PRO', 'stem']], 'word_gloss': 'we'}, {'token': 'egas', 'wPOS': 'N', 'morphemes': [['egas', '@UNK@', 'beras', 'N', 'stem']], 'word_gloss': 'rice'}, {'token': '.', 'wPOS': 'PUNCT', 'morphemes': [['.', '@UNK@', '@UNK@', 'PUNCT', 'punct']], 'word_gloss': 'punct'}]\n",
      "Extraction done...\n",
      "\n",
      "Post filtering statistics:\n",
      "\tTotal words after filtering: 27543\n",
      "\tTotal training examples, after filtering for _surSeg 3955\n",
      "\tTotal punctuation and digits: 0\n",
      "\n",
      "\n",
      "Sanity check training examples:\n",
      " [{'text_title': \"Rey's fiction // 138 Susuad i Rey\", 'text_comment': 'No comment', 'line#': '16', 'free_transl': '@UNK@', 'orig_line': 'uhad tidia igindur ou igkerai kapal ngiriaak .', 'words': [{'token': 'uhad', 'wPOS': 'MO.ACY.M', 'morphemes': [['uhad', '@UNK@', 'leave', 'MO.ACY.M', 'stem']], 'word_gloss': 'leave'}, {'token': 'tidia', 'wPOS': 'Adv.loc', 'morphemes': [['tidia', '@UNK@', '@UNK@', 'Adv.loc', 'stem']], 'word_gloss': '@UNK@'}, {'token': 'igindur', 'wPOS': 'V.ACY.C2', 'morphemes': [['-in-', '@UNK@', 'PST.ACY', 'V.ACY:(PST/NPST)', 'prefix'], ['g-', '@UNK@', 'ACY.C2', 'V>V.ACY.C2', 'prefix'], ['indur', '@UNK@', 'pindah;.memindah;.menggerakkan;.mengalihkan', 'V', 'stem']], 'word_gloss': 'move to different place; to shift (something)'}, {'token': 'ou', 'wPOS': 'PERS.PRO', 'morphemes': [['ou', '@UNK@', 'saya;.aku', 'PERS.PRO', 'stem']], 'word_gloss': 'I'}, {'token': 'igkerai', 'wPOS': 'V.ACY.C2', 'morphemes': [['g-', '@UNK@', 'ACY.C2', 'V>V.ACY.C2', 'prefix'], ['kerai', '@UNK@', 'kerja,.pekerjaan', 'N', 'stem']], 'word_gloss': 'work'}, {'token': 'kapal', 'wPOS': '@UNK@', 'morphemes': [['kapal', '@UNK@', '@UNK@', '@UNK@', 'stem']], 'word_gloss': '@UNK@'}, {'token': 'ngiriaak', 'wPOS': 'V.ISA.AV', 'morphemes': [['ng-', '@UNK@', 'ISA.AV', 'V.ISA>V.ISA.AV', 'prefix'], ['riaak', '@UNK@', 'pull', 'V.ISA', 'stem']], 'word_gloss': 'pull smthg'}, {'token': '.', 'wPOS': 'PUNCT', 'morphemes': [['.', '@UNK@', '@UNK@', 'PUNCT', 'punct']], 'word_gloss': 'punct'}]}, {'text_title': \"Rey's fiction // 138 Susuad i Rey\", 'text_comment': 'No comment', 'line#': '17', 'free_transl': '@UNK@', 'orig_line': 'dia pa lobi na baar ou kerasa susa pasal kosog dodos , gumbakng , dolok , mah panas .', 'words': [{'token': 'dia', 'wPOS': 'Adv.loc', 'morphemes': [['dia', '@UNK@', 'sana', 'Adv.loc', 'stem']], 'word_gloss': 'there'}, {'token': 'pa', 'wPOS': 'TNS', 'morphemes': [['pa', '@UNK@', 'yet', 'TNS', 'stem']], 'word_gloss': 'yet'}, {'token': 'lobi', 'wPOS': 'INTNS', 'morphemes': [['lobi', '@UNK@', 'lebih', 'INTNS', 'stem']], 'word_gloss': 'more'}, {'token': 'na', 'wPOS': 'Det', 'morphemes': [['na', '@UNK@', 'DEF', 'Det', 'stem']], 'word_gloss': 'the'}, {'token': 'baar', 'wPOS': 'V.ST1', 'morphemes': [['baar', '@UNK@', 'betul;.penting;.benar;.tepat', 'ADJ', 'stem']], 'word_gloss': 'true'}, {'token': 'ou', 'wPOS': 'PERS.PRO', 'morphemes': [['ou', '@UNK@', 'saya;.aku', 'PERS.PRO', 'stem']], 'word_gloss': 'I'}, {'token': 'kerasa', 'wPOS': '@UNK@', 'morphemes': [['k-', '@UNK@', '@UNK@', '@UNK@', 'prefix'], ['rasa', '@UNK@', 'rasa', 'N', 'stem']], 'word_gloss': '@UNK@'}, {'token': 'susa', 'wPOS': 'V.ST1', 'morphemes': [['susa', '@UNK@', 'sulit,.sukar', 'V.ST1', 'stem']], 'word_gloss': 'difficult'}, {'token': 'pasal', 'wPOS': 'N', 'morphemes': [['pasal', '@UNK@', 'reason', 'N', 'stem']], 'word_gloss': 'because'}, {'token': 'kosog', 'wPOS': 'V.ST1', 'morphemes': [['kosog', '@UNK@', 'kuat', 'V.ST1', 'stem']], 'word_gloss': 'strong'}, {'token': 'dodos', 'wPOS': 'N', 'morphemes': [['dodos', '@UNK@', 'angin', 'N', 'stem']], 'word_gloss': 'wind'}, {'token': ',', 'wPOS': 'PUNCT', 'morphemes': [[',', '@UNK@', '@UNK@', 'PUNCT', 'punct']], 'word_gloss': 'punct'}, {'token': 'gumbakng', 'wPOS': 'N', 'morphemes': [['gumbakng', '@UNK@', 'ombak', 'N', 'stem']], 'word_gloss': 'waves'}, {'token': ',', 'wPOS': 'PUNCT', 'morphemes': [[',', '@UNK@', '@UNK@', 'PUNCT', 'punct']], 'word_gloss': 'punct'}, {'token': 'dolok', 'wPOS': 'N', 'morphemes': [['dolok', '@UNK@', 'hujan', 'N', 'stem']], 'word_gloss': 'rain'}, {'token': ',', 'wPOS': 'PUNCT', 'morphemes': [[',', '@UNK@', '@UNK@', 'PUNCT', 'punct']], 'word_gloss': 'punct'}, {'token': 'mah', 'wPOS': 'Coordconj', 'morphemes': [['mah', '@UNK@', 'dan', 'Coordconj', 'stem']], 'word_gloss': 'and'}, {'token': 'panas', 'wPOS': 'V.ST1', 'morphemes': [['panas', '@UNK@', 'panas', 'V.ST1', 'stem']], 'word_gloss': 'hot'}, {'token': '.', 'wPOS': 'PUNCT', 'morphemes': [['.', '@UNK@', '@UNK@', 'PUNCT', 'punct']], 'word_gloss': 'punct'}]}, {'text_title': \"Rey's fiction // 138 Susuad i Rey\", 'text_comment': 'No comment', 'line#': '18', 'free_transl': '@UNK@', 'orig_line': 'dia na hei nggien ku inipit toyuk~toyuk siidn .', 'words': [{'token': 'dia', 'wPOS': 'Adv.loc', 'morphemes': [['dia', '@UNK@', 'sana', 'Adv.loc', 'stem']], 'word_gloss': 'there'}, {'token': 'na', 'wPOS': 'Det', 'morphemes': [['na', '@UNK@', 'DEF', 'Det', 'stem']], 'word_gloss': 'the'}, {'token': 'hei', 'wPOS': 'Adv', 'morphemes': [['kai', '@UNK@', 'juga', 'Adv.epis', 'stem']], 'word_gloss': 'also'}, {'token': 'nggien', 'wPOS': 'QW', 'morphemes': [['nggien', '@UNK@', 'di.mana', 'QW', 'stem']], 'word_gloss': 'where'}, {'token': 'ku', 'wPOS': 'PERS.PRO', 'morphemes': [['==ku', '@UNK@', '=', 'PERS.PRO', 'enclitic']], 'word_gloss': 'my'}, {'token': 'inipit', 'wPOS': '@UNK@', 'morphemes': [['inipit', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'toyuk~toyuk', 'wPOS': 'V.ST1', 'morphemes': [['toyuk', '@UNK@', 'kecil;.sedikit', 'V.ST1', 'stem']], 'word_gloss': 'very small'}, {'token': 'siidn', 'wPOS': 'N', 'morphemes': [['siidn', '@UNK@', 'duit;.wang', 'N', 'stem']], 'word_gloss': 'money'}, {'token': '.', 'wPOS': 'PUNCT', 'morphemes': [['.', '@UNK@', '@UNK@', 'PUNCT', 'punct']], 'word_gloss': 'punct'}]}, {'text_title': \"Rey's fiction // 138 Susuad i Rey\", 'text_comment': 'No comment', 'line#': '19', 'free_transl': '@UNK@', 'orig_line': 'na siidn piompodn ku na suat miribu lima atus .', 'words': [{'token': 'na', 'wPOS': 'Det', 'morphemes': [['na', '@UNK@', 'DEF', 'Det', 'stem']], 'word_gloss': 'the'}, {'token': 'siidn', 'wPOS': 'N', 'morphemes': [['siidn', '@UNK@', 'duit;.wang', 'N', 'stem']], 'word_gloss': 'money'}, {'token': 'piompodn', 'wPOS': 'V.ISA.UV', 'morphemes': [['-in-', '@UNK@', 'PST.ACL', 'V.ACL:(PST/NPST)', 'infix'], ['pompodn', '@UNK@', 'menggumpul', 'V', 'stem']], 'word_gloss': 'gather; assemble'}, {'token': 'ku', 'wPOS': 'PERS.PRO', 'morphemes': [['==ku', '@UNK@', '=', 'PERS.PRO', 'enclitic']], 'word_gloss': 'my'}, {'token': 'na', 'wPOS': 'Det', 'morphemes': [['na', '@UNK@', 'DEF', 'Det', 'stem']], 'word_gloss': 'the'}, {'token': 'suat', 'wPOS': 'V', 'morphemes': [['suat', '@UNK@', 'kena', 'V', 'stem']], 'word_gloss': 'hit by'}, {'token': 'miribu', 'wPOS': 'Card.Num', 'morphemes': [['miribu', '@UNK@', 'seribu', 'Card.Num', 'stem']], 'word_gloss': 'one thousand'}, {'token': 'lima', 'wPOS': 'Card.Num', 'morphemes': [['lima', '@UNK@', 'lima', 'Card.Num', 'stem']], 'word_gloss': 'five'}, {'token': 'atus', 'wPOS': 'Card.Num', 'morphemes': [['atus', '@UNK@', 'atus', 'Card.Num', 'stem']], 'word_gloss': 'hundred'}, {'token': '.', 'wPOS': 'PUNCT', 'morphemes': [['.', '@UNK@', '@UNK@', 'PUNCT', 'punct']], 'word_gloss': 'punct'}]}, {'text_title': \"Rey's fiction // 138 Susuad i Rey\", 'text_comment': 'No comment', 'line#': '20', 'free_transl': '@UNK@', 'orig_line': 'ina na , pingegatakng ku languh nu .', 'words': [{'token': 'ina', 'wPOS': 'DEM.PRO', 'morphemes': [['ina', '@UNK@', 'itu', 'DEM.PRO', 'stem']], 'word_gloss': 'that'}, {'token': 'na', 'wPOS': 'Det', 'morphemes': [['na', '@UNK@', 'DEF', 'Det', 'stem']], 'word_gloss': 'the'}, {'token': ',', 'wPOS': 'PUNCT', 'morphemes': [[',', '@UNK@', '@UNK@', 'PUNCT', 'punct']], 'word_gloss': 'punct'}, {'token': 'pingegatakng', 'wPOS': '@UNK@', 'morphemes': [['pingegatakng', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'ku', 'wPOS': 'PERS.PRO', 'morphemes': [['==ku', '@UNK@', '=', 'PERS.PRO', 'enclitic']], 'word_gloss': 'my'}, {'token': 'languh', 'wPOS': 'N', 'morphemes': [['languh', '@UNK@', 'ipar', 'N', 'stem']], 'word_gloss': 'brother~in~law'}, {'token': 'nu', 'wPOS': 'PERS.PRO', 'morphemes': [['nu', '@UNK@', 'engkau;.awak;.saudara;.anda', 'PERS.PRO', 'stem']], 'word_gloss': 'your'}, {'token': '.', 'wPOS': 'PUNCT', 'morphemes': [['.', '@UNK@', '@UNK@', 'PUNCT', 'punct']], 'word_gloss': 'punct'}]}]\n",
      "\n",
      "Sanity check unannotated data:\n",
      " []\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "LANGUAGE: btz\n",
      "Parts of speech found in corpus: {'pro', 'vi', 'relpro', 'Conj', 'v', 'PUNCT', 'prt', 'Prep', 'Aux', 'existmrkr', 'adv', 'refl', 'distrnum', 'cardnum', 'Adj', 'ordnum', 'adj', 'nprop', 'interj', 'vd', 'dem', 'stc', 'quant', 'clf', 'vt', 'n', 'cop'}\n",
      "\n",
      "All Tokens: 4285\n",
      "Lexemes, ignoring punctuation and digits: 3839\n",
      "Initial Extraction Sanity Check: [{'token': 'alkisah', 'wPOS': 'n', 'morphemes': [['alkisah', '@UNK@', 'The.story.is.told', 'n', 'stem']], 'word_gloss': 'The story is told'}, {'token': ',', 'wPOS': 'PUNCT', 'morphemes': [[',', '@UNK@', '@UNK@', 'PUNCT', 'punct']], 'word_gloss': 'punct'}, {'token': 'ni', 'wPOS': 'Prep', 'morphemes': [['ni', '@UNK@', 'in,.at.(space)', 'Prep', 'stem']], 'word_gloss': 'in, at (space)'}, {'token': 'sebuah', 'wPOS': 'distrnum', 'morphemes': [['sebuah', '@UNK@', 'one', 'distrnum', 'stem']], 'word_gloss': 'one'}, {'token': 'kute', 'wPOS': 'n', 'morphemes': [['kute', '@UNK@', 'city', 'n', 'stem']], 'word_gloss': 'city'}, {'token': '(', 'wPOS': 'PUNCT', 'morphemes': [['(', '@UNK@', '@UNK@', 'PUNCT', 'punct']], 'word_gloss': 'punct'}, {'token': 'kute', 'wPOS': 'n', 'morphemes': [['kute', '@UNK@', 'city', 'n', 'stem']], 'word_gloss': 'city'}, {'token': 'neggekhi', 'wPOS': 'nprop', 'morphemes': [['neggekhi', 'neggekhi', 'Nagari', 'nprop', 'stem']], 'word_gloss': 'Nagari'}, {'token': 'desa', 'wPOS': 'n', 'morphemes': [['desa', '@UNK@', 'village', 'n', 'stem']], 'word_gloss': 'desa'}, {'token': ')', 'wPOS': 'PUNCT', 'morphemes': [[')', '@UNK@', '@UNK@', 'PUNCT', 'punct']], 'word_gloss': 'punct'}]\n",
      "Extraction done...\n",
      "\n",
      "Post filtering statistics:\n",
      "\tTotal words after filtering: 4285\n",
      "\tTotal training examples, after filtering for _surSeg 302\n",
      "\tTotal punctuation and digits: 0\n",
      "\n",
      "\n",
      "Sanity check training examples:\n",
      " [{'text_title': 'The Morphology System of Verbs in the Alas Language - Example Sentences // Sistem Morfologi Kata Kerja Bahas Alas - Kalimat Contoh', 'text_comment': 'These are example sentences from a verb grammar', 'line#': '80', 'free_transl': '@UNK@', 'orig_line': 'tawe cikhemi kidhah aku bhone .', 'words': [{'token': 'tawe cikhemi', 'wPOS': 'vt', 'morphemes': [['tawe', '@UNK@', 'laugh,.to', 'v', 'stem'], ['cikhem', '@UNK@', 'smile,.to', 'v', 'stem'], ['-i', '@UNK@', 'REPEATEDLY', 'v>vt', 'suffix']], 'word_gloss': 'to smile at'}, {'token': 'kidhah', 'wPOS': 'pro', 'morphemes': [['kidah', '@UNK@', '1sg', 'pro', 'stem']], 'word_gloss': '1sg'}, {'token': 'aku', 'wPOS': 'pro', 'morphemes': [['aku', '@UNK@', '1sg', 'pro', 'stem']], 'word_gloss': 'I'}, {'token': 'bhone', 'wPOS': 'n', 'morphemes': [['bhone', '@UNK@', 'yesterday', 'n', 'stem']], 'word_gloss': 'yesterday'}, {'token': '.', 'wPOS': 'PUNCT', 'morphemes': [['.', '@UNK@', '@UNK@', 'PUNCT', 'punct']], 'word_gloss': 'punct'}]}, {'text_title': 'The Morphology System of Verbs in the Alas Language - Example Sentences // Sistem Morfologi Kata Kerja Bahas Alas - Kalimat Contoh', 'text_comment': 'These are example sentences from a verb grammar', 'line#': '81', 'free_transl': '@UNK@', 'orig_line': 'bhabhai mbhalik anak~anak edhi kekhine', 'words': [{'token': 'bhabhai mbhalik', 'wPOS': 'vt', 'morphemes': [['bhabhe', '@UNK@', 'to.carry', 'v', 'stem'], ['-i', '@UNK@', 'REPEATEDLY', 'v>vt', 'suffix'], ['m-', '@UNK@', 'TRANS', 'v:Any', 'prefix'], ['bhalik', '@UNK@', 'return.home,.to', 'vi', 'stem']], 'word_gloss': 'bring home'}, {'token': 'anak~anak', 'wPOS': 'n', 'morphemes': [['[...]--', '@UNK@', 'PLURAL', 'n:Any', 'prefix'], ['anak', '@UNK@', 'child', 'n', 'stem']], 'word_gloss': 'children'}, {'token': 'edhi', 'wPOS': 'dem', 'morphemes': [['edhi', '@UNK@', 'that,.those', 'dem', 'stem']], 'word_gloss': 'that'}, {'token': 'kekhine', 'wPOS': 'adj', 'morphemes': [['kekhine', '@UNK@', 'all', 'adj', 'stem']], 'word_gloss': 'all'}]}, {'text_title': 'The Morphology System of Verbs in the Alas Language - Example Sentences // Sistem Morfologi Kata Kerja Bahas Alas - Kalimat Contoh', 'text_comment': 'These are example sentences from a verb grammar', 'line#': '82', 'free_transl': '@UNK@', 'orig_line': 'iyeme si mbhabheken mbhalik kekade edhi .', 'words': [{'token': 'iyeme', 'wPOS': 'pro', 'morphemes': [['ie', '@UNK@', '3sg', 'pro', 'stem'], ['-me', '@UNK@', 'EMPHASIS', '???>???', 'suffix']], 'word_gloss': 'he'}, {'token': 'si', 'wPOS': 'relpro', 'morphemes': [['si', '@UNK@', 'relpro', 'relpro', 'stem']], 'word_gloss': 'one who, the one which'}, {'token': 'mbhabheken mbhalik', 'wPOS': 'vt', 'morphemes': [['m-', '@UNK@', 'TRANS', 'v:Any', 'prefix'], ['bhabhe', '@UNK@', 'to.carry', 'v', 'stem'], ['-ken', '<nken', 'CAUSATIVE', 'v>vt', 'suffix'], ['m-', '@UNK@', 'TRANS', 'v:Any', 'prefix'], ['bhalik', '@UNK@', 'return.home,.to', 'vi', 'stem']], 'word_gloss': 'to brin home'}, {'token': 'kekade', 'wPOS': 'n', 'morphemes': [['kekade', '@UNK@', 'thing,.item', 'n', 'stem']], 'word_gloss': 'thing'}, {'token': 'edhi', 'wPOS': 'dem', 'morphemes': [['edhi', '@UNK@', 'that,.those', 'dem', 'stem']], 'word_gloss': 'that'}, {'token': '.', 'wPOS': 'PUNCT', 'morphemes': [['.', '@UNK@', '@UNK@', 'PUNCT', 'punct']], 'word_gloss': 'punct'}]}, {'text_title': 'The Morphology System of Verbs in the Alas Language - Example Sentences // Sistem Morfologi Kata Kerja Bahas Alas - Kalimat Contoh', 'text_comment': 'These are example sentences from a verb grammar', 'line#': '83', 'free_transl': '@UNK@', 'orig_line': 'uanme si ngelausken mece nanak endhe be ndokhsah .', 'words': [{'token': 'uanme', 'wPOS': 'n', 'morphemes': [['uan', '@UNK@', 'dad', 'n', 'stem'], ['-me', '@UNK@', 'EMPHASIS', '???>???', 'suffix']], 'word_gloss': 'father'}, {'token': 'si', 'wPOS': 'relpro', 'morphemes': [['si', '@UNK@', 'relpro', 'relpro', 'stem']], 'word_gloss': 'one who, the one which'}, {'token': 'ngelausken mece', 'wPOS': 'vt', 'morphemes': [['nge-', 'n>ken', 'CAUSATIVE', 'v>vt', 'prefix'], ['laus', '@UNK@', 'go', 'v', 'stem'], ['-ken', '<nken', 'CAUSATIVE', 'v>vt', 'suffix'], ['mece', '@UNK@', 'to.read.holy.books', 'vi', 'stem']], 'word_gloss': 'to bring to learn religion'}, {'token': 'nanak', 'wPOS': 'n', 'morphemes': [['nanak', '@UNK@', 'children', 'n', 'stem']], 'word_gloss': 'children'}, {'token': 'endhe', 'wPOS': 'pro', 'morphemes': [['endhe', '@UNK@', 'it', 'pro', 'stem']], 'word_gloss': 'it'}, {'token': 'be', 'wPOS': 'Prep', 'morphemes': [['bhe', '@UNK@', 'to,..toward.(a.place)', 'Prep', 'stem']], 'word_gloss': 'to,  toward (a place)'}, {'token': 'ndokhsah', 'wPOS': 'n', 'morphemes': [['ndokhsah', '@UNK@', 'Muslim.house.of.worship', 'n', 'stem']], 'word_gloss': 'Muslim house of worship'}, {'token': '.', 'wPOS': 'PUNCT', 'morphemes': [['.', '@UNK@', '@UNK@', 'PUNCT', 'punct']], 'word_gloss': 'punct'}]}, {'text_title': 'The Morphology System of Verbs in the Alas Language - Example Sentences // Sistem Morfologi Kata Kerja Bahas Alas - Kalimat Contoh', 'text_comment': 'These are example sentences from a verb grammar', 'line#': '84', 'free_transl': '@UNK@', 'orig_line': 'anakdhi agup numpang kepalingken aku .', 'words': [{'token': 'anakdhi', 'wPOS': 'n', 'morphemes': [['anak', '@UNK@', 'child', 'n', 'stem'], ['edhi', '@UNK@', 'that,.those', 'dem', 'stem']], 'word_gloss': 'that child'}, {'token': 'agup', 'wPOS': 'vt', 'morphemes': [['agup', '@UNK@', 'to.be.capable.of', 'vt', 'stem']], 'word_gloss': 'to be capable of'}, {'token': 'numpang kepalingken', 'wPOS': 'vt', 'morphemes': [['n-', 'n>ken', 'CAUSATIVE', 'v>vt', 'prefix'], ['tumpang', '@UNK@', 'to.somersault', 'vt', 'stem'], ['kepaling', '@UNK@', 'to.turn', 'vi', 'stem'], ['-ken', '<nken', 'CAUSATIVE', 'v>vt', 'suffix']], 'word_gloss': 'to turn upside down'}, {'token': 'aku', 'wPOS': 'pro', 'morphemes': [['aku', '@UNK@', '1sg', 'pro', 'stem']], 'word_gloss': 'I'}, {'token': '.', 'wPOS': 'PUNCT', 'morphemes': [['.', '@UNK@', '@UNK@', 'PUNCT', 'punct']], 'word_gloss': 'punct'}]}]\n",
      "\n",
      "Sanity check unannotated data:\n",
      " []\n",
      "\n",
      "\n",
      "LANGUAGE: cho\n",
      "Parts of speech found in corpus: {'suffix', 'pro', 'v', 'conj', 'PUNCT', 'prt', 'phrase', 'indefinite', 'adv', 'post', 'proform', 'interrogative', '@UNK@', 'verbprt', 'num', 'adj', 'directional', 'preverb', 'determiner,.pronoun', 'interj', 'preposition', 'possessive.pronoun', 'n', 'determiner', 'exclamation'}\n",
      "\n",
      "All Tokens: 9962\n",
      "Lexemes, ignoring punctuation and digits: 7814\n",
      "Initial Extraction Sanity Check: [{'token': 'himak nittak', 'wPOS': 'n', 'morphemes': [['himak.nittak', '@UNK@', 'TODAY,.THIS.DAY', 'n', 'phrase']], 'word_gloss': 'today'}, {'token': ',', 'wPOS': 'PUNCT', 'morphemes': [[',', '@UNK@', '@UNK@', 'PUNCT', 'punct']], 'word_gloss': 'punct'}, {'token': 'aha̱ttali', 'wPOS': 'v', 'morphemes': [['aha̱tta', '@UNK@', 'STAY,.LIVE.(SOMEPLACE)', 'v', 'stem'], ['-li', '@UNK@', '1SI', 'v:(1sI)', 'suffix']], 'word_gloss': 'I’m living'}, {'token': 'píh', 'wPOS': 'adv', 'morphemes': [['pí', '@UNK@', 'just', 'adv', 'stem']], 'word_gloss': 'just'}, {'token': 'aha̱ttali', 'wPOS': 'v', 'morphemes': [['aha̱tta', '@UNK@', 'STAY,.LIVE.(SOMEPLACE)', 'v', 'stem'], ['-li', '@UNK@', '1SI', 'v:(1sI)', 'suffix']], 'word_gloss': 'I’m living'}, {'token': 'tokbá', 'wPOS': '@UNK@', 'morphemes': [['tokbá', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'hitoko̱', 'wPOS': 'conj', 'morphemes': [['hitoko̱', '@UNK@', '@UNK@', 'conj', 'stem']], 'word_gloss': '@UNK@'}, {'token': ',', 'wPOS': 'PUNCT', 'morphemes': [[',', '@UNK@', '@UNK@', 'PUNCT', 'punct']], 'word_gloss': 'punct'}]\n",
      "Extraction done...\n",
      "\n",
      "Post filtering statistics:\n",
      "\tTotal words after filtering: 9962\n",
      "\tTotal training examples, after filtering for _surSeg 1441\n",
      "\tTotal punctuation and digits: 0\n",
      "\n",
      "\n",
      "Sanity check training examples:\n",
      " [{'text_title': 'Christine Joe interview 2001003_Source_Source.wav', 'text_comment': 'No comment', 'line#': '151', 'free_transl': '@UNK@', 'orig_line': 'anakmako , hihátoko̱ mihchit pisálikmat', 'words': [{'token': 'anakmako', 'wPOS': '@UNK@', 'morphemes': [['anakmako', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': ',', 'wPOS': 'PUNCT', 'morphemes': [[',', '@UNK@', '@UNK@', 'PUNCT', 'punct']], 'word_gloss': 'punct'}, {'token': 'hihátoko̱', 'wPOS': '@UNK@', 'morphemes': [['hihátoko̱', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'mihchit', 'wPOS': '@UNK@', 'morphemes': [['mihchi', '@UNK@', '@UNK@', 'v', 'stem'], ['-t', '@UNK@', '@UNK@', 'v:(tense)', 'suffix']], 'word_gloss': '@UNK@'}, {'token': 'pisálikmat', 'wPOS': '@UNK@', 'morphemes': [['pisálikmat', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}]}, {'text_title': 'Christine Joe interview 2001003_Source_Source.wav', 'text_comment': 'No comment', 'line#': '152', 'free_transl': '@UNK@', 'orig_line': 'ilappat ik alhpísotoka̱ , áha̱hnilih akínih anakínih mako .', 'words': [{'token': 'ilappat', 'wPOS': 'determiner', 'morphemes': [['ilappat', '@UNK@', '@UNK@', 'determiner', 'stem']], 'word_gloss': '@UNK@'}, {'token': 'ik', 'wPOS': '@UNK@', 'morphemes': [['ik-', '@UNK@', 'N', 'v:Any', 'prefix']], 'word_gloss': '@UNK@'}, {'token': 'alhpísotoka̱', 'wPOS': '@UNK@', 'morphemes': [['alhpísotoka̱', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': ',', 'wPOS': 'PUNCT', 'morphemes': [[',', '@UNK@', '@UNK@', 'PUNCT', 'punct']], 'word_gloss': 'punct'}, {'token': 'áha̱hnilih', 'wPOS': '@UNK@', 'morphemes': [['áha̱hnilih', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'akínih', 'wPOS': '@UNK@', 'morphemes': [['akínih', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'anakínih', 'wPOS': '@UNK@', 'morphemes': [['ano', '@UNK@', 'I', 'pro', 'stem'], ['-aki̱li', '@UNK@', 'INDEED', 'v:(adv2)', 'suffix']], 'word_gloss': '@UNK@'}, {'token': 'mako', 'wPOS': '@UNK@', 'morphemes': [['mako', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': '.', 'wPOS': 'PUNCT', 'morphemes': [['.', '@UNK@', '@UNK@', 'PUNCT', 'punct']], 'word_gloss': 'punct'}]}, {'text_title': 'Christine Joe interview 2001003_Source_Source.wav', 'text_comment': 'No comment', 'line#': '153', 'free_transl': '@UNK@', 'orig_line': 'hikako̱ achokmáh pí mihchikmako̱ ish ikkanáchi̱h akínih pí .', 'words': [{'token': 'hikako̱', 'wPOS': '@UNK@', 'morphemes': [['hikako̱', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'achokmáh', 'wPOS': '@UNK@', 'morphemes': [['im.achokma', '@UNK@', '@UNK@', 'v', 'stem'], ['-h', '@UNK@', '@UNK@', 'v:(tense)', 'suffix']], 'word_gloss': '@UNK@'}, {'token': 'pí', 'wPOS': 'adv', 'morphemes': [['pí', '@UNK@', 'JUST', 'adv', 'stem']], 'word_gloss': '@UNK@'}, {'token': 'mihchikmako̱', 'wPOS': '@UNK@', 'morphemes': [['mihchikmako̱', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'ish', 'wPOS': 'verbprt', 'morphemes': [['ish', '@UNK@', 'YOU', 'Attaches.to.any.category', 'prefix']], 'word_gloss': '@UNK@'}, {'token': 'ikkanáchi̱h', 'wPOS': '@UNK@', 'morphemes': [['ikkanáchi̱h', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'akínih', 'wPOS': '@UNK@', 'morphemes': [['akínih', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'pí', 'wPOS': 'adv', 'morphemes': [['pí', '@UNK@', 'JUST', 'adv', 'stem']], 'word_gloss': '@UNK@'}, {'token': '.', 'wPOS': 'PUNCT', 'morphemes': [['.', '@UNK@', '@UNK@', 'PUNCT', 'punct']], 'word_gloss': 'punct'}]}, {'text_title': 'Christine Joe interview 2001003_Source_Source.wav', 'text_comment': 'No comment', 'line#': '154', 'free_transl': '@UNK@', 'orig_line': 'hihátoko̱ ná anno̱pa ato lawwat mapillaho̱ makalánah akínih másh yohmi hikakósh pí', 'words': [{'token': 'hihátoko̱', 'wPOS': '@UNK@', 'morphemes': [['hihátoko̱', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'ná', 'wPOS': 'n', 'morphemes': [['ná', '@UNK@', 'SOMETHING', 'n', 'stem']], 'word_gloss': '@UNK@'}, {'token': 'anno̱pa', 'wPOS': 'n', 'morphemes': [['anno̱pa', '@UNK@', 'word', 'n', 'stem']], 'word_gloss': 'word'}, {'token': 'ato', 'wPOS': '@UNK@', 'morphemes': [['-ato', '@UNK@', 'NOM2', 'n:(case)', 'suffix']], 'word_gloss': '@UNK@'}, {'token': 'lawwat', 'wPOS': '@UNK@', 'morphemes': [['lawwat', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'mapillaho̱', 'wPOS': '@UNK@', 'morphemes': [['mapillaho̱', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'makalánah', 'wPOS': '@UNK@', 'morphemes': [['makalánah', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'akínih', 'wPOS': '@UNK@', 'morphemes': [['akínih', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'másh', 'wPOS': 'pro', 'morphemes': [['másh', '@UNK@', 'that.one', 'pro', 'stem']], 'word_gloss': '@UNK@'}, {'token': 'yohmi', 'wPOS': '@UNK@', 'morphemes': [['yohmi', '@UNK@', 'do.so,.to.happen', 'v', 'stem']], 'word_gloss': '@UNK@'}, {'token': 'hikakósh', 'wPOS': '@UNK@', 'morphemes': [['hikakósh', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'pí', 'wPOS': 'adv', 'morphemes': [['pí', '@UNK@', 'JUST', 'adv', 'stem']], 'word_gloss': '@UNK@'}]}, {'text_title': 'Christine Joe interview 2001003_Source_Source.wav', 'text_comment': 'No comment', 'line#': '155', 'free_transl': '@UNK@', 'orig_line': 'ná mapillakano makálih kíyo pí pash alhlhilih fokkáli .', 'words': [{'token': 'ná', 'wPOS': 'n', 'morphemes': [['ná', '@UNK@', 'SOMETHING', 'n', 'stem']], 'word_gloss': '@UNK@'}, {'token': 'mapillakano', 'wPOS': '@UNK@', 'morphemes': [['mapillakano', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'makálih', 'wPOS': '@UNK@', 'morphemes': [['maká', '@UNK@', '@UNK@', 'v', 'stem'], ['-li', '@UNK@', '@UNK@', 'v:(1sI)', 'suffix'], ['-h', '@UNK@', '@UNK@', 'v:(tense)', 'suffix']], 'word_gloss': '@UNK@'}, {'token': 'kíyo', 'wPOS': 'exclamation', 'morphemes': [['kiyo', '@UNK@', 'no', 'interj', 'stem']], 'word_gloss': 'no'}, {'token': 'pí', 'wPOS': 'adv', 'morphemes': [['pí', '@UNK@', 'JUST', 'adv', 'stem']], 'word_gloss': '@UNK@'}, {'token': 'pash', 'wPOS': '@UNK@', 'morphemes': [['pash', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'alhlhilih', 'wPOS': '@UNK@', 'morphemes': [['alhlhilih', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'fokkáli', 'wPOS': 'v', 'morphemes': [['fokkáli', '@UNK@', 'be:about', 'adv', 'stem']], 'word_gloss': 'be:about'}, {'token': '.', 'wPOS': 'PUNCT', 'morphemes': [['.', '@UNK@', '@UNK@', 'PUNCT', 'punct']], 'word_gloss': 'punct'}]}]\n",
      "\n",
      "Sanity check unannotated data:\n",
      " [{'text_title': 'Barbara and Ruth interview [22002_Source_StandardAudio (1)_Source.wav]', 'text_comment': 'No comment', 'line#': '210', 'free_transl': '@UNK@', 'orig_line': 'nánit okla yohmáhíkiyoh ma [ no ].', 'words': [{'token': 'nánit', 'wPOS': '@UNK@', 'morphemes': [['nánit', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'okla', 'wPOS': 'n', 'morphemes': [['okla', '@UNK@', 'PEOPLE', 'n', 'stem']], 'word_gloss': 'plural'}, {'token': 'yohmáhíkiyoh', 'wPOS': '@UNK@', 'morphemes': [['yohmáhíkiyoh', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'ma', 'wPOS': '@UNK@', 'morphemes': [['@UNK@', '@UNK@', '@UNK@', '@UNK@', 'stem']], 'word_gloss': '@UNK@'}, {'token': '[', 'wPOS': 'PUNCT', 'morphemes': [['[', '@UNK@', '@UNK@', 'PUNCT', 'punct']], 'word_gloss': 'punct'}, {'token': 'no', 'wPOS': '@UNK@', 'morphemes': [['no', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': '].', 'wPOS': 'PUNCT', 'morphemes': [['].', '@UNK@', '@UNK@', 'PUNCT', 'punct']], 'word_gloss': 'punct'}]}, {'text_title': 'Barbara and Ruth interview [22002_Source_StandardAudio (1)_Source.wav]', 'text_comment': 'No comment', 'line#': '358', 'free_transl': '@UNK@', 'orig_line': 'nána okla hapim ábachih , ish áchásh [ áchi chásh ]', 'words': [{'token': 'nána', 'wPOS': 'n', 'morphemes': [['nána', '@UNK@', 'something', 'n', 'stem']], 'word_gloss': '@UNK@'}, {'token': 'okla', 'wPOS': 'n', 'morphemes': [['okla', '@UNK@', 'PEOPLE', 'n', 'stem']], 'word_gloss': 'plural'}, {'token': 'hapim', 'wPOS': '@UNK@', 'morphemes': [['hapim-', '@UNK@', '1MPIII', 'n:(poss)', 'prefix']], 'word_gloss': '@UNK@'}, {'token': 'ábachih', 'wPOS': 'v', 'morphemes': [['ábachi', '@UNK@', 'teach', 'v', 'stem'], ['-h', '@UNK@', 'TNS', 'v:(tense)', 'suffix']], 'word_gloss': '@UNK@'}, {'token': ',', 'wPOS': 'PUNCT', 'morphemes': [[',', '@UNK@', '@UNK@', 'PUNCT', 'punct']], 'word_gloss': 'punct'}, {'token': 'ish', 'wPOS': 'verbprt', 'morphemes': [['ish', '@UNK@', 'YOU', 'Attaches.to.any.category', 'prefix']], 'word_gloss': '@UNK@'}, {'token': 'áchásh', 'wPOS': '@UNK@', 'morphemes': [['áchásh', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': '[', 'wPOS': 'PUNCT', 'morphemes': [['[', '@UNK@', '@UNK@', 'PUNCT', 'punct']], 'word_gloss': 'punct'}, {'token': 'áchi', 'wPOS': '@UNK@', 'morphemes': [['@UNK@', '@UNK@', '@UNK@', '@UNK@', 'stem']], 'word_gloss': '@UNK@'}, {'token': 'chásh', 'wPOS': '@UNK@', 'morphemes': [['chásh', '@UNK@', '@UNK@', '@UNK@', 'stem']], 'word_gloss': '@UNK@'}, {'token': ']', 'wPOS': 'PUNCT', 'morphemes': [[']', '@UNK@', '@UNK@', 'PUNCT', 'punct']], 'word_gloss': 'punct'}]}, {'text_title': 'Barbara and Ruth interview [22002_Source_StandardAudio (1)_Source.wav]', 'text_comment': 'No comment', 'line#': '372', 'free_transl': '@UNK@', 'orig_line': 'chim ábachílánah \" áchi ná \" óh [ ómih ]\" álittók .', 'words': [{'token': 'chim', 'wPOS': '@UNK@', 'morphemes': [['chim', '@UNK@', '2sIII', '<Not.Sure>', 'stem']], 'word_gloss': '@UNK@'}, {'token': 'ábachílánah', 'wPOS': '@UNK@', 'morphemes': [['ábachílánah', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': '\"', 'wPOS': 'PUNCT', 'morphemes': [['\"', '@UNK@', '@UNK@', 'PUNCT', 'punct']], 'word_gloss': 'punct'}, {'token': 'áchi', 'wPOS': '@UNK@', 'morphemes': [['@UNK@', '@UNK@', '@UNK@', '@UNK@', 'stem']], 'word_gloss': '@UNK@'}, {'token': 'ná', 'wPOS': 'n', 'morphemes': [['ná', '@UNK@', 'SOMETHING', 'n', 'stem']], 'word_gloss': '@UNK@'}, {'token': '\"', 'wPOS': 'PUNCT', 'morphemes': [['\"', '@UNK@', '@UNK@', 'PUNCT', 'punct']], 'word_gloss': 'punct'}, {'token': 'óh', 'wPOS': '@UNK@', 'morphemes': [['óh', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': '[', 'wPOS': 'PUNCT', 'morphemes': [['[', '@UNK@', '@UNK@', 'PUNCT', 'punct']], 'word_gloss': 'punct'}, {'token': 'ómih', 'wPOS': '@UNK@', 'morphemes': [['ómih', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': ']\"', 'wPOS': 'PUNCT', 'morphemes': [[']\"', '@UNK@', '@UNK@', 'PUNCT', 'punct']], 'word_gloss': 'punct'}, {'token': 'álittók', 'wPOS': '@UNK@', 'morphemes': [['álittók', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': '.', 'wPOS': 'PUNCT', 'morphemes': [['.', '@UNK@', '@UNK@', 'PUNCT', 'punct']], 'word_gloss': 'punct'}]}, {'text_title': 'Christine Joe interview 2001003_Source_Source.wav', 'text_comment': 'No comment', 'line#': '46', 'free_transl': '@UNK@', 'orig_line': 'yoh [ mi ] ma achokmah okla il áyyásha amahówah , kiyo [ á ] chínih kako̱', 'words': [{'token': 'yoh', 'wPOS': '@UNK@', 'morphemes': [['yoh', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': '[', 'wPOS': 'PUNCT', 'morphemes': [['[', '@UNK@', '@UNK@', 'PUNCT', 'punct']], 'word_gloss': 'punct'}, {'token': 'mi', 'wPOS': '@UNK@', 'morphemes': [['mi', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': ']', 'wPOS': 'PUNCT', 'morphemes': [[']', '@UNK@', '@UNK@', 'PUNCT', 'punct']], 'word_gloss': 'punct'}, {'token': 'ma', 'wPOS': '@UNK@', 'morphemes': [['@UNK@', '@UNK@', '@UNK@', '@UNK@', 'stem']], 'word_gloss': '@UNK@'}, {'token': 'achokmah', 'wPOS': '@UNK@', 'morphemes': [['achokma', '@UNK@', '@UNK@', 'v', 'stem'], ['-h', '@UNK@', '@UNK@', 'v:(tense)', 'suffix']], 'word_gloss': '@UNK@'}, {'token': 'okla', 'wPOS': 'n', 'morphemes': [['okla', '@UNK@', 'PEOPLE', 'n', 'stem']], 'word_gloss': 'plural'}, {'token': 'il', 'wPOS': '@UNK@', 'morphemes': [['il-', '@UNK@', '1PI', 'v:(Iagr)', 'prefix']], 'word_gloss': '@UNK@'}, {'token': 'áyyásha', 'wPOS': '@UNK@', 'morphemes': [['áyyásha', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'amahówah', 'wPOS': '@UNK@', 'morphemes': [['amahówah', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': ',', 'wPOS': 'PUNCT', 'morphemes': [[',', '@UNK@', '@UNK@', 'PUNCT', 'punct']], 'word_gloss': 'punct'}, {'token': 'kiyo', 'wPOS': 'adv', 'morphemes': [['kiyo', '@UNK@', 'not', '<Not.Sure>', 'stem']], 'word_gloss': '@UNK@'}, {'token': '[', 'wPOS': 'PUNCT', 'morphemes': [['[', '@UNK@', '@UNK@', 'PUNCT', 'punct']], 'word_gloss': 'punct'}, {'token': 'á', 'wPOS': 'v', 'morphemes': [['á', '@UNK@', 'be', 'v', 'stem']], 'word_gloss': 'from'}, {'token': ']', 'wPOS': 'PUNCT', 'morphemes': [[']', '@UNK@', '@UNK@', 'PUNCT', 'punct']], 'word_gloss': 'punct'}, {'token': 'chínih', 'wPOS': '@UNK@', 'morphemes': [['chínih', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'kako̱', 'wPOS': '@UNK@', 'morphemes': [['kako̱', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}]}, {'text_title': 'Christine Joe interview 2001003_Source_Source.wav', 'text_comment': 'No comment', 'line#': '100', 'free_transl': '@UNK@', 'orig_line': 'december ónakmako himo shilosh , lokka ahwah tobáchi , ná tanna áchi ,', 'words': [{'token': 'december', 'wPOS': '@UNK@', 'morphemes': [['december', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'ónakmako', 'wPOS': '@UNK@', 'morphemes': [['ónakmako', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'himo', 'wPOS': '@UNK@', 'morphemes': [['himo', '@UNK@', 'right:now', 'conj', 'stem']], 'word_gloss': '@UNK@'}, {'token': 'shilosh', 'wPOS': 'n', 'morphemes': [['sholosh', '@UNK@', 'shoes', 'n', 'stem']], 'word_gloss': 'shoes'}, {'token': ',', 'wPOS': 'PUNCT', 'morphemes': [[',', '@UNK@', '@UNK@', 'PUNCT', 'punct']], 'word_gloss': 'punct'}, {'token': 'lokka', 'wPOS': 'n', 'morphemes': [['lokka', '@UNK@', 'clothes', 'n', 'stem']], 'word_gloss': '@UNK@'}, {'token': 'ahwah', 'wPOS': '@UNK@', 'morphemes': [['ahwa', '@UNK@', 'think.(perhaps),.to.reckon', 'v', 'stem'], ['-h', '@UNK@', 'TNS', 'v:(tense)', 'suffix']], 'word_gloss': '@UNK@'}, {'token': 'tobáchi', 'wPOS': 'v', 'morphemes': [['tobáchi', '@UNK@', 'turn:on.', 'v', 'stem']], 'word_gloss': 'turn on (lights)'}, {'token': ',', 'wPOS': 'PUNCT', 'morphemes': [[',', '@UNK@', '@UNK@', 'PUNCT', 'punct']], 'word_gloss': 'punct'}, {'token': 'ná', 'wPOS': 'n', 'morphemes': [['ná', '@UNK@', 'SOMETHING', 'n', 'stem']], 'word_gloss': '@UNK@'}, {'token': 'tanna', 'wPOS': '@UNK@', 'morphemes': [['tanna', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'áchi', 'wPOS': '@UNK@', 'morphemes': [['@UNK@', '@UNK@', '@UNK@', '@UNK@', 'stem']], 'word_gloss': '@UNK@'}, {'token': ',', 'wPOS': 'PUNCT', 'morphemes': [[',', '@UNK@', '@UNK@', 'PUNCT', 'punct']], 'word_gloss': 'punct'}]}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "LANGUAGE: lez\n",
      "Parts of speech found in corpus: {'pro', 'poss', 'Voc.part', 'v', 'PUNCT', 'IMPV', 'prt', 'prep', 'adv', 'post', 'emph', 'indfpro', 'subordconn', 'proform', '@UNK@', 'verbprt', 'interrog', 'num', 'cardnum', 'ordnum', 'adj', 'multipnum', 'pers', 'nprop', 'interj', 'det', 'dem', 'conn', 'coordconn', 'recp', 'n', 'cop'}\n",
      "\n",
      "All Tokens: 18750\n",
      "Lexemes, ignoring punctuation and digits: 13953\n",
      "Initial Extraction Sanity Check: [{'token': 'са', 'wPOS': 'cardnum', 'morphemes': [['са', '@UNK@', 'one', 'cardnum', 'stem']], 'word_gloss': 'one'}, {'token': 'юкъуз', 'wPOS': 'n', 'morphemes': [['юкъ', '@UNK@', '@UNK@', '@UNK@', 'stem'], ['-ди', '@UNK@', 'OBL', 'n:Oblique-erg', 'suffix'], ['-з', '@UNK@', 'DAT', 'n:SemCase', 'suffix']], 'word_gloss': 'day'}, {'token': 'зун', 'wPOS': 'pers', 'morphemes': [['зун', '@UNK@', '@UNK@', '@UNK@', 'stem']], 'word_gloss': '1sg.abs'}, {'token': 'хуьряй', 'wPOS': 'n', 'morphemes': [['хуьр', '@UNK@', 'village', '<Not.Sure>', 'stem'], ['-да', '@UNK@', 'IN', 'n:InPreCase', 'suffix'], ['-ай', '@UNK@', 'EL', 'n:DirCASE', 'suffix']], 'word_gloss': 'from village'}, {'token': 'кцӏариз', 'wPOS': 'nprop', 'morphemes': [['кцӏар', '@UNK@', '@UNK@', '@UNK@', 'stem'], ['-ди', '@UNK@', 'OBL', 'n:Oblique-erg', 'suffix'], ['-з', '@UNK@', 'DAT', 'n:SemCase', 'suffix']], 'word_gloss': 'gusar'}, {'token': 'хквезвай', 'wPOS': 'v', 'morphemes': [['хт', '@UNK@', 'return', 'v..(UEA)', 'stem'], ['-зава', '@UNK@', 'IMPF', 'v:TMimpf', 'suffix'], ['-й', '@UNK@', 'PTCP', 'v:PTCP', 'suffix']], 'word_gloss': 'return'}, {'token': 'тир', 'wPOS': 'cop', 'morphemes': [['тир', '@UNK@', 'was', 'cop', 'stem']], 'word_gloss': 'COP~PST'}, {'token': ',', 'wPOS': 'PUNCT', 'morphemes': [[',', '@UNK@', '@UNK@', 'PUNCT', 'punct']], 'word_gloss': 'punct'}, {'token': 'рекъе', 'wPOS': 'n', 'morphemes': [['рекъ', '@UNK@', 'way,.road', 'n', 'stem'], ['е', '@UNK@', '@UNK@', '@UNK@', 'stem']], 'word_gloss': 'way.in'}, {'token': 'са', 'wPOS': 'cardnum', 'morphemes': [['са', '@UNK@', 'one', 'cardnum', 'stem']], 'word_gloss': 'one'}]\n",
      "Extraction done...\n",
      "\n",
      "Post filtering statistics:\n",
      "\tTotal words after filtering: 18750\n",
      "\tTotal training examples, after filtering for _surSeg 1531\n",
      "\tTotal punctuation and digits: 0\n",
      "\n",
      "\n",
      "Sanity check training examples:\n",
      " [{'text_title': \"Afiya's Engagement // 17 Лишанлу Афиядирн\", 'text_comment': 'No comment', 'line#': '38', 'free_transl': '@UNK@', 'orig_line': 'гьа вили чкадиз зун фида .', 'words': [{'token': 'гьа', 'wPOS': 'dem', 'morphemes': [['гьа', '@UNK@', 'that,.the.same', 'dem', 'stem']], 'word_gloss': 'that'}, {'token': 'вили', 'wPOS': 'adj', 'morphemes': [['вили', '@UNK@', 'blue', 'adj', 'stem']], 'word_gloss': 'blue'}, {'token': 'чкадиз', 'wPOS': 'n', 'morphemes': [['чка', '@UNK@', 'place', 'n', 'stem'], ['-ди', '@UNK@', 'OBL', 'n:Oblique-erg', 'suffix'], ['-з', '@UNK@', 'DAT', 'n:SemCase', 'suffix']], 'word_gloss': 'place.from'}, {'token': 'зун', 'wPOS': 'pers', 'morphemes': [['зун', '@UNK@', '@UNK@', '@UNK@', 'stem']], 'word_gloss': 'I'}, {'token': 'фида', 'wPOS': 'v', 'morphemes': [['ф', '@UNK@', 'go', 'v..(IIE)', 'stem'], ['-да', '@UNK@', 'FUT', 'v:indTA', 'suffix']], 'word_gloss': 'go~FUT'}, {'token': '.', 'wPOS': 'PUNCT', 'morphemes': [['.', '@UNK@', '@UNK@', 'PUNCT', 'punct']], 'word_gloss': 'punct'}]}, {'text_title': \"Afiya's Engagement // 17 Лишанлу Афиядирн\", 'text_comment': 'No comment', 'line#': '39', 'free_transl': '@UNK@', 'orig_line': 'гьа , сонра ..', 'words': [{'token': 'гьа', 'wPOS': 'dem', 'morphemes': [['гьа', '@UNK@', 'that,.the.same', 'dem', 'stem']], 'word_gloss': 'that'}, {'token': ',', 'wPOS': 'PUNCT', 'morphemes': [[',', '@UNK@', '@UNK@', 'PUNCT', 'punct']], 'word_gloss': 'punct'}, {'token': 'сонра', 'wPOS': 'adv', 'morphemes': [['сонра', '@UNK@', 'after', 'adv', 'stem']], 'word_gloss': 'after'}, {'token': '..', 'wPOS': 'PUNCT', 'morphemes': [['..', '@UNK@', '@UNK@', 'PUNCT', 'punct']], 'word_gloss': 'punct'}]}, {'text_title': \"Afiya's Engagement // 17 Лишанлу Афиядирн\", 'text_comment': 'No comment', 'line#': '40', 'free_transl': '@UNK@', 'orig_line': 'ха ха ха', 'words': [{'token': 'ха', 'wPOS': 'interj', 'morphemes': [['ха', '@UNK@', 'ha', 'interj', 'stem']], 'word_gloss': 'ha'}, {'token': 'ха', 'wPOS': 'interj', 'morphemes': [['ха', '@UNK@', 'ha', 'interj', 'stem']], 'word_gloss': 'ha'}, {'token': 'ха', 'wPOS': 'interj', 'morphemes': [['ха', '@UNK@', 'ha', 'interj', 'stem']], 'word_gloss': 'ha'}]}, {'text_title': \"Afiya's Engagement // 17 Лишанлу Афиядирн\", 'text_comment': 'No comment', 'line#': '41', 'free_transl': '@UNK@', 'orig_line': 'сонра къарлай , варцарлай , вобщем , дуьз хьана вири , зун лишанлу хьана майдиз .', 'words': [{'token': 'сонра', 'wPOS': 'adv', 'morphemes': [['сонра', '@UNK@', 'after', 'adv', 'stem']], 'word_gloss': 'after'}, {'token': 'къарлай', 'wPOS': 'n', 'morphemes': [['къар', '@UNK@', 'days', '<Not.Sure>', 'stem'], ['л', '@UNK@', '@UNK@', '@UNK@', 'stem'], ['-ай', '@UNK@', 'EL', 'n:DirCASE', 'suffix']], 'word_gloss': 'days'}, {'token': ',', 'wPOS': 'PUNCT', 'morphemes': [[',', '@UNK@', '@UNK@', 'PUNCT', 'punct']], 'word_gloss': 'punct'}, {'token': 'варцарлай', 'wPOS': 'n', 'morphemes': [['варц', '@UNK@', 'month', 'n', 'stem'], ['-ар', '@UNK@', 'PL', 'n:(NUMBER)', 'suffix'], ['-л', '@UNK@', 'SP', 'n:SPpreCase', 'suffix'], ['-ай', '@UNK@', 'EL', 'n:DirCASE', 'suffix']], 'word_gloss': 'month'}, {'token': ',', 'wPOS': 'PUNCT', 'morphemes': [[',', '@UNK@', '@UNK@', 'PUNCT', 'punct']], 'word_gloss': 'punct'}, {'token': 'вобщем', 'wPOS': 'adv', 'morphemes': [['вобщем', '@UNK@', 'anyway', 'prt', 'stem']], 'word_gloss': 'anyway'}, {'token': ',', 'wPOS': 'PUNCT', 'morphemes': [[',', '@UNK@', '@UNK@', 'PUNCT', 'punct']], 'word_gloss': 'punct'}, {'token': 'дуьз', 'wPOS': 'adv', 'morphemes': [['дуьз', '@UNK@', 'great', 'adv', 'stem']], 'word_gloss': 'great'}, {'token': 'хьана', 'wPOS': 'cop', 'morphemes': [['хьун', '@UNK@', 'be', 'cop', 'stem'], ['на', '@UNK@', '@UNK@', '@UNK@', 'stem']], 'word_gloss': 'be'}, {'token': 'вири', 'wPOS': 'pro', 'morphemes': [['вири', '@UNK@', 'all', 'pro', 'stem']], 'word_gloss': 'all'}, {'token': ',', 'wPOS': 'PUNCT', 'morphemes': [[',', '@UNK@', '@UNK@', 'PUNCT', 'punct']], 'word_gloss': 'punct'}, {'token': 'зун', 'wPOS': 'pers', 'morphemes': [['зун', '@UNK@', '@UNK@', '@UNK@', 'stem']], 'word_gloss': 'I'}, {'token': 'лишанлу', 'wPOS': 'adj', 'morphemes': [['лишанлу', '@UNK@', 'engagament', 'adj', 'stem']], 'word_gloss': 'engagament'}, {'token': 'хьана', 'wPOS': '@UNK@', 'morphemes': [['хьун', '@UNK@', 'be', 'cop', 'stem'], ['на', '@UNK@', '@UNK@', '@UNK@', 'stem']], 'word_gloss': '@UNK@'}, {'token': 'майдиз', 'wPOS': 'n', 'morphemes': [['май', '@UNK@', 'May', 'nprop', 'stem'], ['-ди', '@UNK@', 'OBL', 'n:Oblique-erg', 'suffix'], ['-з', '@UNK@', 'DAT', 'n:SemCase', 'suffix']], 'word_gloss': 'May'}, {'token': '.', 'wPOS': 'PUNCT', 'morphemes': [['.', '@UNK@', '@UNK@', 'PUNCT', 'punct']], 'word_gloss': 'punct'}]}, {'text_title': \"Afiya's Engagement // 17 Лишанлу Афиядирн\", 'text_comment': 'No comment', 'line#': '42', 'free_transl': '@UNK@', 'orig_line': 'майдиз лишанлу хьана , сентябрдиз чун эвли хьана .', 'words': [{'token': 'майдиз', 'wPOS': 'n', 'morphemes': [['май', '@UNK@', 'May', 'nprop', 'stem'], ['-ди', '@UNK@', 'OBL', 'n:Oblique-erg', 'suffix'], ['-з', '@UNK@', 'DAT', 'n:SemCase', 'suffix']], 'word_gloss': 'May'}, {'token': 'лишанлу', 'wPOS': 'adj', 'morphemes': [['лишанлу', '@UNK@', 'engagament', 'adj', 'stem']], 'word_gloss': 'engagament'}, {'token': 'хьана', 'wPOS': '@UNK@', 'morphemes': [['хьун', '@UNK@', 'be', '<Not.Sure>', 'stem'], ['на', '@UNK@', '@UNK@', '@UNK@', 'stem']], 'word_gloss': '@UNK@'}, {'token': ',', 'wPOS': 'PUNCT', 'morphemes': [[',', '@UNK@', '@UNK@', 'PUNCT', 'punct']], 'word_gloss': 'punct'}, {'token': 'сентябрдиз', 'wPOS': 'n', 'morphemes': [['сентябр', '@UNK@', 'september', 'nprop', 'stem'], ['-ди', '@UNK@', 'OBL', 'n:Oblique-erg', 'suffix'], ['-з', '@UNK@', 'DAT', 'n:SemCase', 'suffix']], 'word_gloss': 'September'}, {'token': 'чун', 'wPOS': 'pro', 'morphemes': [['чун', '@UNK@', '1pl.abs', 'pro', 'stem']], 'word_gloss': 'we'}, {'token': 'эвли', 'wPOS': 'n', 'morphemes': [['эвли', '@UNK@', 'married', '<Not.Sure>', 'stem']], 'word_gloss': 'married'}, {'token': 'хьана', 'wPOS': 'cop', 'morphemes': [['хьун', '@UNK@', 'be', 'cop', 'stem'], ['на', '@UNK@', '@UNK@', '@UNK@', 'stem']], 'word_gloss': 'be'}, {'token': '.', 'wPOS': 'PUNCT', 'morphemes': [['.', '@UNK@', '@UNK@', 'PUNCT', 'punct']], 'word_gloss': 'punct'}]}]\n",
      "\n",
      "Sanity check unannotated data:\n",
      " []\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "LANGUAGE: ntu\n",
      "Parts of speech found in corpus: {'INTJ', 'V.(caus)', 'pro', 'be.V.', 'Pers.pro', 'Nom.phrase', 'Ord', 'CONJ', 'PCLF', 'PUNCT', 'VP', 'PN', 'NEG', 'N', 'z-Nom', 'Particle', 'N.comp', 'V.(comp)', 'NP', 'N(kx.cl)', 'vi.', 'GEN', 'vt.', '@UNK@', 'interrog', 'num', 'Phrase', 'V', 'Adj', 'Det', 'nprop', 'Nom1', 'PREP', 'RPRN', 'NP.(comp)', 'Clause', 'Adv', 'A-D-P2', 'DEM', 'NUM', 'V.neg', 'C-fix-Nom', 'Poss.pro', 'SUBR'}\n",
      "\n",
      "All Tokens: 20054\n",
      "Lexemes, ignoring punctuation and digits: 16690\n",
      "Initial Extraction Sanity Check: [{'token': '29', 'wPOS': 'num', 'morphemes': [['29', '29', 'NUM', '@UNK@', 'stem']], 'word_gloss': '@UNK@'}, {'token': '.', 'wPOS': 'PUNCT', 'morphemes': [['.', '@UNK@', '@UNK@', 'PUNCT', 'punct']], 'word_gloss': 'punct'}, {'token': 'vex', 'wPOS': '@UNK@', 'morphemes': [['ve', '@UNK@', 'accompany', 'V', 'stem'], ['==ä', '@UNK@', '=1ᴍꞮɴI', 'Nom1', 'enclitic']], 'word_gloss': '@UNK@'}, {'token': 'dckta foks', 'wPOS': '@UNK@', 'morphemes': [['dckta.foks', '@UNK@', '@UNK@', '@UNK@', 'stem']], 'word_gloss': '@UNK@'}, {'token': 'mz', 'wPOS': 'PREP', 'morphemes': [['më', '@UNK@', 'ᴘʀᴇᴘ', 'PREP', 'stem']], 'word_gloss': 'in'}, {'token': 'nzamukxtr~krde', 'wPOS': '@UNK@', 'morphemes': [['në-', '@UNK@', 'ɴᴍʟᴢ1', 'V>N', 'prefix'], ['a-', '@UNK@', 'ᴄᴀᴜЅ', 'V:Any', 'prefix'], ['mu', '@UNK@', 'eat', 'V', 'stem'], ['kä..', '@UNK@', 'ѕᴜʙʀ', 'SUBR', 'stem'], ['tö', '@UNK@', 'holy', 'V', 'stem'], ['-kö', '@UNK@', 'ɴᴍʟᴢ.ᴘᴄꜰʟ', 'V>N', 'suffix'], ['==de', '@UNK@', '=3ᴍꞮɴII', 'A-D-P2', 'enclitic']], 'word_gloss': '@UNK@'}, {'token': 'pawa', 'wPOS': '@UNK@', 'morphemes': [['pawa', '@UNK@', 'Pawa.school', 'N', 'stem']], 'word_gloss': '@UNK@'}, {'token': 'skul', 'wPOS': 'V', 'morphemes': [['skul', '@UNK@', 'be.schooled', 'V', 'stem']], 'word_gloss': 'school'}]\n",
      "Extraction done...\n",
      "\n",
      "Post filtering statistics:\n",
      "\tTotal words after filtering: 20054\n",
      "\tTotal training examples, after filtering for _surSeg 1606\n",
      "\tTotal punctuation and digits: 0\n",
      "\n",
      "\n",
      "Sanity check training examples:\n",
      " [{'text_title': 'zzz1st story ntu-boys-AW04', 'text_comment': 'No comment', 'line#': '2', 'free_transl': '@UNK@', 'orig_line': \"mzneyagwengrkc tqkzsilenide ncblo keycnebade dese sctqpipebale mrlem lvemibz mzdwakc rlatir medisin kc bade dalrngr nemqlengr xkxmule lc ncblo xmrle neiscn medisin nemncngr mztea x tenru tenru klangu keneyagwe ngxpipepwem olvzkcma xncm mznryagwengrlc kc tqkasilenim c dwanem ncblo lcde se medisin kxnzrmqlengr ncblo yrlwr olbaut mztea leu kxnz ius ngrde nzrtibalr mz mrlxkcmz' kabxle medisin x mqlxkcmz' dcwa nede tqyagwe ngxepe x loule xpipele leu kxxble neepipeelr olvzkc tqpiba bade myxkcmnqlvakrde xpule kxini dckta rpiba dwakc kctiini dckta\", 'words': [{'token': 'mzneyagwengrkc', 'wPOS': '@UNK@', 'morphemes': [['mzneyagwengrkc', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'tqkzsilenide', 'wPOS': '@UNK@', 'morphemes': [['tqkzsilenide', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'ncblo', 'wPOS': 'N', 'morphemes': [['nâblo', '@UNK@', 'man', 'N', 'stem']], 'word_gloss': 'man'}, {'token': 'keycnebade', 'wPOS': '@UNK@', 'morphemes': [['keycnebade', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'dese', 'wPOS': 'Clause', 'morphemes': [['dese', '@UNK@', 'here.it.is', 'Clause', 'stem']], 'word_gloss': 'here.it.is'}, {'token': 'sctqpipebale', 'wPOS': '@UNK@', 'morphemes': [['sctqpipebale', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'mrlem', 'wPOS': '@UNK@', 'morphemes': [['mrlem', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'lvemibz', 'wPOS': '@UNK@', 'morphemes': [['lvemibz', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'mzdwakc', 'wPOS': '@UNK@', 'morphemes': [['mzdwakc', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'rlatir', 'wPOS': '@UNK@', 'morphemes': [['rlatir', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'medisin', 'wPOS': '@UNK@', 'morphemes': [['medisin', '@UNK@', '@UNK@', '@UNK@', 'stem']], 'word_gloss': '@UNK@'}, {'token': 'kc', 'wPOS': 'RPRN', 'morphemes': [['kâ', '@UNK@', 'ᴅᴇᴍ2.ᴅꞮЅᴛ', '@UNK@', 'stem']], 'word_gloss': 'which'}, {'token': 'bade', 'wPOS': 'A-D-P2', 'morphemes': [['ba-', '@UNK@', 'ᴅᴀᴛ', 'A-D-P2', 'stem'], ['==de', '@UNK@', '=3ᴍꞮɴII', 'A-D-P2', 'enclitic']], 'word_gloss': 'to him'}, {'token': 'dalrngr', 'wPOS': 'V', 'morphemes': [['dalö', '@UNK@', 'things.of', 'RPRN', 'stem'], ['-ngö', '@UNK@', 'ᴠƦ', 'N>be.V.', 'suffix']], 'word_gloss': 'things.of'}, {'token': 'nemqlengr', 'wPOS': '@UNK@', 'morphemes': [['nemqle', '@UNK@', '@UNK@', '@UNK@', 'stem'], ['-ngö', '@UNK@', 'ᴀᴘᴘʟ', 'V:(APP)', 'suffix']], 'word_gloss': '@UNK@'}, {'token': 'xkxmule', 'wPOS': '@UNK@', 'morphemes': [['xkxmule', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'lc', 'wPOS': 'Det', 'morphemes': [['lâ', '@UNK@', 'ᴅᴇᴍ1.ᴅɪѕᴛ', 'DEM', 'stem']], 'word_gloss': 'this'}, {'token': 'ncblo', 'wPOS': 'N', 'morphemes': [['nâblo', '@UNK@', 'man', 'N', 'stem']], 'word_gloss': 'man'}, {'token': 'xmrle', 'wPOS': '@UNK@', 'morphemes': [['xmrle', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'neiscn', 'wPOS': '@UNK@', 'morphemes': [['neiscn', '@UNK@', '@UNK@', '@UNK@', 'stem']], 'word_gloss': '@UNK@'}, {'token': 'medisin', 'wPOS': '@UNK@', 'morphemes': [['medisin', '@UNK@', '@UNK@', '@UNK@', 'stem']], 'word_gloss': '@UNK@'}, {'token': 'nemncngr', 'wPOS': '@UNK@', 'morphemes': [['nemncngr', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'mztea', 'wPOS': 'N', 'morphemes': [['mëtea', '@UNK@', 'village', 'N', 'stem']], 'word_gloss': 'village'}, {'token': 'x', 'wPOS': 'CONJ', 'morphemes': [['ä', '@UNK@', 'and', 'CONJ', 'stem']], 'word_gloss': 'and'}, {'token': 'tenru', 'wPOS': '@UNK@', 'morphemes': [['tenru', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'tenru', 'wPOS': '@UNK@', 'morphemes': [['tenru', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'klangu', 'wPOS': '@UNK@', 'morphemes': [['klangu', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'keneyagwe', 'wPOS': '@UNK@', 'morphemes': [['keneyagwe', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'ngxpipepwem', 'wPOS': '@UNK@', 'morphemes': [['ngxpipepwem', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'olvzkcma', 'wPOS': '@UNK@', 'morphemes': [['olvë', '@UNK@', 'wife', 'N', 'stem'], ['kâ', '@UNK@', 'ᴅᴇᴍ2.ᴅɪѕᴛ', 'DEM', 'stem'], ['-ma', '@UNK@', 'SPEC', 'DEM:Any', 'suffix']], 'word_gloss': '@UNK@'}, {'token': 'xncm', 'wPOS': '@UNK@', 'morphemes': [['xncm', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'mznryagwengrlc', 'wPOS': '@UNK@', 'morphemes': [['mënö', '@UNK@', 'empty', 'V', 'stem'], ['-yagwe', '@UNK@', '@UNK@', '@UNK@', 'stem'], ['-ngö', '@UNK@', 'ᴀᴘᴘʟ', 'V:(APP)', 'suffix'], ['-lc', '@UNK@', '@UNK@', '@UNK@', 'stem']], 'word_gloss': '@UNK@'}, {'token': 'kc', 'wPOS': 'RPRN', 'morphemes': [['kâ', '@UNK@', 'ᴅᴇᴍ2.ᴅꞮЅᴛ', '@UNK@', 'stem']], 'word_gloss': 'which'}, {'token': 'tqkasilenim', 'wPOS': '@UNK@', 'morphemes': [['tqkasilenim', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'c', 'wPOS': '@UNK@', 'morphemes': [['c', '@UNK@', '@UNK@', '@UNK@', 'stem']], 'word_gloss': '@UNK@'}, {'token': 'dwanem', 'wPOS': '@UNK@', 'morphemes': [['dwanem', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'ncblo', 'wPOS': 'N', 'morphemes': [['nâblo', '@UNK@', 'man', 'N', 'stem']], 'word_gloss': 'man'}, {'token': 'lcde', 'wPOS': 'Adv', 'morphemes': [['lâde', '@UNK@', 'there', 'Adv', 'stem']], 'word_gloss': 'there'}, {'token': 'se', 'wPOS': 'Adv', 'morphemes': [['se', '@UNK@', 'here', 'Adv', 'stem']], 'word_gloss': 'here'}, {'token': 'medisin', 'wPOS': '@UNK@', 'morphemes': [['medisin', '@UNK@', '@UNK@', '@UNK@', 'stem']], 'word_gloss': '@UNK@'}, {'token': 'kxnzrmqlengr', 'wPOS': '@UNK@', 'morphemes': [['kxnzrmqle', '@UNK@', '@UNK@', '@UNK@', 'stem'], ['-ngö', '@UNK@', 'ᴀᴘᴘʟ', 'V:(APP)', 'suffix']], 'word_gloss': '@UNK@'}, {'token': 'ncblo', 'wPOS': 'N', 'morphemes': [['nâblo', '@UNK@', 'man', 'N', 'stem']], 'word_gloss': 'man'}, {'token': 'yrlwr', 'wPOS': 'V', 'morphemes': [['yölwö', '@UNK@', 'gather', 'V', 'stem']], 'word_gloss': 'gather'}, {'token': 'olbaut', 'wPOS': '@UNK@', 'morphemes': [['olbaut', '@UNK@', '@UNK@', '@UNK@', 'stem']], 'word_gloss': '@UNK@'}, {'token': 'mztea', 'wPOS': 'N', 'morphemes': [['mëtea', '@UNK@', 'village', 'N', 'stem']], 'word_gloss': 'village'}, {'token': 'leu', 'wPOS': 'N', 'morphemes': [['leu', '@UNK@', 'leaf', 'N', 'stem']], 'word_gloss': 'leaf'}, {'token': 'kxnz', 'wPOS': '@UNK@', 'morphemes': [['kxnz', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'ius', 'wPOS': '@UNK@', 'morphemes': [['ius', '@UNK@', '@UNK@', '@UNK@', 'stem']], 'word_gloss': '@UNK@'}, {'token': 'ngrde', 'wPOS': 'Poss.pro', 'morphemes': [['ngö', '@UNK@', 'ɢᴇɴ1ᴀ', 'GEN', 'stem'], ['==de', '@UNK@', '=3ᴍꞮɴII', 'A-D-P2', 'enclitic']], 'word_gloss': '3min.poss'}, {'token': 'nzrtibalr', 'wPOS': '@UNK@', 'morphemes': [['nzrtibalr', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'mz', 'wPOS': 'PREP', 'morphemes': [['më', '@UNK@', 'ᴘʀᴇᴘ', 'PREP', 'stem']], 'word_gloss': 'PREP'}, {'token': \"mrlxkcmz'\", 'wPOS': '@UNK@', 'morphemes': [[\"mrlxkcmz'\", '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'kabxle', 'wPOS': '@UNK@', 'morphemes': [['kabxle', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'medisin', 'wPOS': '@UNK@', 'morphemes': [['medisin', '@UNK@', '@UNK@', '@UNK@', 'stem']], 'word_gloss': '@UNK@'}, {'token': 'x', 'wPOS': 'CONJ', 'morphemes': [['ä', '@UNK@', 'and', 'CONJ', 'stem']], 'word_gloss': 'and'}, {'token': \"mqlxkcmz'\", 'wPOS': '@UNK@', 'morphemes': [[\"mqlxkcmz'\", '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'dcwa', 'wPOS': '@UNK@', 'morphemes': [['dcwa', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'nede', 'wPOS': 'Poss.pro', 'morphemes': [['ne', '@UNK@', 'ᴘᴄꜰʟ.rsbl', 'Particle', 'stem'], ['==de', '@UNK@', '=3ᴍꞮɴII', 'A-D-P2', 'enclitic']], 'word_gloss': 'his'}, {'token': 'tqyagwe', 'wPOS': '@UNK@', 'morphemes': [['tqyagwe', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'ngxepe', 'wPOS': '@UNK@', 'morphemes': [['ngxepe', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'x', 'wPOS': 'CONJ', 'morphemes': [['ä', '@UNK@', 'and', 'CONJ', 'stem']], 'word_gloss': 'and'}, {'token': 'loule', 'wPOS': '@UNK@', 'morphemes': [['loule', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'xpipele', 'wPOS': '@UNK@', 'morphemes': [['xpipele', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'leu', 'wPOS': 'N', 'morphemes': [['leu', '@UNK@', 'leaf', 'N', 'stem']], 'word_gloss': 'leaf'}, {'token': 'kxxble', 'wPOS': '@UNK@', 'morphemes': [['kxxble', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'neepipeelr', 'wPOS': '@UNK@', 'morphemes': [['neepipeelr', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'olvzkc', 'wPOS': '@UNK@', 'morphemes': [['olvë', '@UNK@', 'wife', 'N', 'stem'], ['kâ', '@UNK@', 'ᴅᴇᴍ2.ᴅɪѕᴛ', 'DEM', 'stem']], 'word_gloss': '@UNK@'}, {'token': 'tqpiba', 'wPOS': '@UNK@', 'morphemes': [['tqpiba', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'bade', 'wPOS': 'A-D-P2', 'morphemes': [['ba-', '@UNK@', 'ᴅᴀᴛ', 'A-D-P2', 'stem'], ['==de', '@UNK@', '=3ᴍꞮɴII', 'A-D-P2', 'enclitic']], 'word_gloss': 'to him'}, {'token': 'myxkcmnqlvakrde', 'wPOS': '@UNK@', 'morphemes': [['myxkcmnqlvakrde', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'xpule', 'wPOS': '@UNK@', 'morphemes': [['xpule', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'kxini', 'wPOS': '@UNK@', 'morphemes': [['kxini', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'dckta', 'wPOS': 'N', 'morphemes': [['dâkta', '@UNK@', 'doctor', 'N', 'stem']], 'word_gloss': 'doctor'}, {'token': 'rpiba', 'wPOS': '@UNK@', 'morphemes': [['rpiba', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'dwakc', 'wPOS': '@UNK@', 'morphemes': [['dwakc', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'kctiini', 'wPOS': '@UNK@', 'morphemes': [['kctiini', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'dckta', 'wPOS': 'N', 'morphemes': [['dâkta', '@UNK@', 'doctor', 'N', 'stem']], 'word_gloss': 'doctor'}]}, {'text_title': 'zzz1st story ntu-boys-AW04', 'text_comment': 'No comment', 'line#': '3', 'free_transl': '@UNK@', 'orig_line': 'tinipwru olvzlcpwz kzdu ncblokz .', 'words': [{'token': 'tinipwru', 'wPOS': '@UNK@', 'morphemes': [['tinipwru', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'olvzlcpwz', 'wPOS': '@UNK@', 'morphemes': [['olvë', '@UNK@', 'wife', 'N', 'stem'], ['-lcpwz', '@UNK@', '@UNK@', '@UNK@', 'stem']], 'word_gloss': '@UNK@'}, {'token': 'kzdu', 'wPOS': 'Det', 'morphemes': [['këdu', '@UNK@', 'some', 'Det', 'stem']], 'word_gloss': 'some'}, {'token': 'ncblokz', 'wPOS': '@UNK@', 'morphemes': [['nâblo', '@UNK@', 'man', 'N', 'stem'], ['-kz', '@UNK@', '@UNK@', '@UNK@', 'stem']], 'word_gloss': '@UNK@'}, {'token': '.', 'wPOS': 'PUNCT', 'morphemes': [['.', '@UNK@', '@UNK@', 'PUNCT', 'punct']], 'word_gloss': 'punct'}]}, {'text_title': 'zzz1st story ntu-boys-AW04', 'text_comment': 'No comment', 'line#': '4', 'free_transl': '@UNK@', 'orig_line': \"ncblo kx prkitq datxde delc talulzkapq doa kcmle kzmule esz' nrprngr nryagewngr kxetu vzm metrabrkitr drtwr delape batrpnengr dckta nidr la tamqlzping nr keneyagwengr nzrpingr ngzturba medisin nzrtingrba medisin nedr mztea nyzdr nectingrbr medisin scdr .\", 'words': [{'token': 'ncblo', 'wPOS': 'N', 'morphemes': [['nâblo', '@UNK@', 'man', 'N', 'stem']], 'word_gloss': 'man'}, {'token': 'kx', 'wPOS': 'Particle', 'morphemes': [['kä..', '@UNK@', 'ѕᴜʙʀ', 'SUBR', 'stem']], 'word_gloss': 'subordinator'}, {'token': 'prkitq', 'wPOS': '@UNK@', 'morphemes': [['prkitq', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'datxde', 'wPOS': '@UNK@', 'morphemes': [['datxde', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'delc', 'wPOS': 'RPRN', 'morphemes': [['delâ', '@UNK@', 'this', 'RPRN', 'stem']], 'word_gloss': 'from that'}, {'token': 'talulzkapq', 'wPOS': '@UNK@', 'morphemes': [['talulzkapq', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'doa', 'wPOS': 'N', 'morphemes': [['doa', '@UNK@', 'child', 'N', 'stem']], 'word_gloss': 'child'}, {'token': 'kcmle', 'wPOS': '@UNK@', 'morphemes': [['kcmle', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'kzmule', 'wPOS': '@UNK@', 'morphemes': [['kzmule', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': \"esz'\", 'wPOS': 'V', 'morphemes': [[\"esë'\", '@UNK@', 'one', 'be.V.', 'stem']], 'word_gloss': 'one'}, {'token': 'nrprngr', 'wPOS': '@UNK@', 'morphemes': [['nöpö', '@UNK@', 'season', 'N', 'stem'], ['-ngö', '@UNK@', 'ᴀᴘᴘʟ', 'V:(APP)', 'suffix']], 'word_gloss': '@UNK@'}, {'token': 'nryagewngr', 'wPOS': '@UNK@', 'morphemes': [['nryagew', '@UNK@', '@UNK@', '@UNK@', 'stem'], ['-ngö', '@UNK@', 'ᴀᴘᴘʟ', 'V:(APP)', 'suffix']], 'word_gloss': '@UNK@'}, {'token': 'kxetu', 'wPOS': 'N(kx.cl)', 'morphemes': [['kä..', '@UNK@', 'ѕᴜʙʀ', 'SUBR', 'stem'], ['etu', '@UNK@', 'big', 'V', 'stem']], 'word_gloss': 'big'}, {'token': 'vzm', 'wPOS': 'V', 'morphemes': [['vë', '@UNK@', 'go', 'V', 'stem'], ['-mü', '@UNK@', 'PᴅꞮƦ.HITHER', 'V:(PDIR)', 'suffix'], ['==', '@UNK@', '=3ᴍꞮɴIS', 'Nom1', 'enclitic']], 'word_gloss': 'come'}, {'token': 'metrabrkitr', 'wPOS': '@UNK@', 'morphemes': [['metrabrkitr', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'drtwr', 'wPOS': 'N', 'morphemes': [['dötwö', '@UNK@', 'mind', 'N', 'stem']], 'word_gloss': 'mind'}, {'token': 'delape', 'wPOS': 'N', 'morphemes': [['delape', '@UNK@', 'hem.nao', 'N', 'stem']], 'word_gloss': 'hem.nao'}, {'token': 'batrpnengr', 'wPOS': '@UNK@', 'morphemes': [['batrpne', '@UNK@', '@UNK@', '@UNK@', 'stem'], ['-ngö', '@UNK@', 'ᴀᴘᴘʟ', 'V:(APP)', 'suffix']], 'word_gloss': '@UNK@'}, {'token': 'dckta', 'wPOS': 'N', 'morphemes': [['dâkta', '@UNK@', 'doctor', 'N', 'stem']], 'word_gloss': 'doctor'}, {'token': 'nidr', 'wPOS': 'Pers.pro', 'morphemes': [['nidö', '@UNK@', 'be.3ᴀᴜɢII.', 'A-D-P2', 'stem']], 'word_gloss': 'them'}, {'token': 'la', 'wPOS': 'DEM', 'morphemes': [['la', '@UNK@', 'ᴅᴇᴍ1.ᴘʀᴏχ', 'DEM', 'stem']], 'word_gloss': 'DEM1'}, {'token': 'tamqlzping', 'wPOS': '@UNK@', 'morphemes': [['tamqlzping', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'nr', 'wPOS': 'PCLF', 'morphemes': [['nö', '@UNK@', 'ᴘᴄꜰʟ.feel', '<Not.Sure>', 'stem']], 'word_gloss': 'PCLF9'}, {'token': 'keneyagwengr', 'wPOS': '@UNK@', 'morphemes': [['keneyagwengr', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'nzrpingr', 'wPOS': '@UNK@', 'morphemes': [['nzrpingr', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'ngzturba', 'wPOS': '@UNK@', 'morphemes': [['ngzturba', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'medisin', 'wPOS': '@UNK@', 'morphemes': [['medisin', '@UNK@', '@UNK@', '@UNK@', 'stem']], 'word_gloss': '@UNK@'}, {'token': 'nzrtingrba', 'wPOS': '@UNK@', 'morphemes': [['nzrtingrba', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'medisin', 'wPOS': '@UNK@', 'morphemes': [['medisin', '@UNK@', '@UNK@', '@UNK@', 'stem']], 'word_gloss': '@UNK@'}, {'token': 'nedr', 'wPOS': 'pro', 'morphemes': [['ne', '@UNK@', 'ᴘᴄꜰʟ.rsbl', 'Particle', 'stem'], ['==dö', '@UNK@', '=3ᴀᴜɢII', 'A-D-P2', 'enclitic']], 'word_gloss': 'their'}, {'token': 'mztea', 'wPOS': 'N', 'morphemes': [['mëtea', '@UNK@', 'village', 'N', 'stem']], 'word_gloss': 'village'}, {'token': 'nyzdr', 'wPOS': 'PCLF', 'morphemes': [['nyë', '@UNK@', 'ᴘᴄꜰʟ.ʙ&ɢ', 'PCLF', 'stem'], ['==dö', '@UNK@', '=3ᴀᴜɢII', '@UNK@', 'enclitic']], 'word_gloss': 'their'}, {'token': 'nectingrbr', 'wPOS': '@UNK@', 'morphemes': [['nectingrbr', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'medisin', 'wPOS': '@UNK@', 'morphemes': [['medisin', '@UNK@', '@UNK@', '@UNK@', 'stem']], 'word_gloss': '@UNK@'}, {'token': 'scdr', 'wPOS': 'Poss.pro', 'morphemes': [['sâ', '@UNK@', 'ᴘᴄꜰʟ.hand', 'PCLF', 'stem'], ['==dö', '@UNK@', '=3ᴀᴜɢII', 'A-D-P2', 'enclitic']], 'word_gloss': 'their'}, {'token': '.', 'wPOS': 'PUNCT', 'morphemes': [['.', '@UNK@', '@UNK@', 'PUNCT', 'punct']], 'word_gloss': 'punct'}]}, {'text_title': 'zzz1st story ntu-boys-AW04', 'text_comment': 'No comment', 'line#': '5', 'free_transl': '@UNK@', 'orig_line': \"kcmule esz' dckta mncmzlika nrklztikz nide nryagwengrlc tqycbange medisin ngrde satqycba mz ncblokc sxtxctipeba satqlvzpingrba ngzxbaukrbaule medisin kc x dckta ncwrngr xmrle twzq\", 'words': [{'token': 'kcmule', 'wPOS': '@UNK@', 'morphemes': [['kcmule', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': \"esz'\", 'wPOS': 'V', 'morphemes': [[\"esë'\", '@UNK@', 'one', 'be.V.', 'stem']], 'word_gloss': 'one'}, {'token': 'dckta', 'wPOS': 'N', 'morphemes': [['dâkta', '@UNK@', 'doctor', 'N', 'stem']], 'word_gloss': 'doctor'}, {'token': 'mncmzlika', 'wPOS': '@UNK@', 'morphemes': [['mncmzlika', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'nrklztikz', 'wPOS': '@UNK@', 'morphemes': [['nrklztikz', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'nide', 'wPOS': 'Pers.pro', 'morphemes': [['nide', '@UNK@', 'be.3ᴍɪɴII', 'A-D-P2', 'stem']], 'word_gloss': 'him'}, {'token': 'nryagwengrlc', 'wPOS': '@UNK@', 'morphemes': [['nryagwengrlc', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'tqycbange', 'wPOS': '@UNK@', 'morphemes': [['tqycbange', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'medisin', 'wPOS': '@UNK@', 'morphemes': [['medisin', '@UNK@', '@UNK@', '@UNK@', 'stem']], 'word_gloss': '@UNK@'}, {'token': 'ngrde', 'wPOS': 'Poss.pro', 'morphemes': [['ngö', '@UNK@', 'ɢᴇɴ1ᴀ', 'GEN', 'stem'], ['==de', '@UNK@', '=3ᴍꞮɴII', 'A-D-P2', 'enclitic']], 'word_gloss': '3min.poss'}, {'token': 'satqycba', 'wPOS': '@UNK@', 'morphemes': [['satqycba', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'mz', 'wPOS': 'PREP', 'morphemes': [['më', '@UNK@', 'ᴘʀᴇᴘ', 'PREP', 'stem']], 'word_gloss': 'PREP'}, {'token': 'ncblokc', 'wPOS': '@UNK@', 'morphemes': [['nâblo', '@UNK@', 'man', 'N', 'stem'], ['kâ', '@UNK@', 'ᴅᴇᴍ2.ᴅɪѕᴛ', 'DEM', 'stem']], 'word_gloss': '@UNK@'}, {'token': 'sxtxctipeba', 'wPOS': '@UNK@', 'morphemes': [['sxtxctipeba', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'satqlvzpingrba', 'wPOS': '@UNK@', 'morphemes': [['satqlvzpingrba', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'ngzxbaukrbaule', 'wPOS': '@UNK@', 'morphemes': [['ngzxbaukrbaule', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'medisin', 'wPOS': '@UNK@', 'morphemes': [['medisin', '@UNK@', '@UNK@', '@UNK@', 'stem']], 'word_gloss': '@UNK@'}, {'token': 'kc', 'wPOS': 'RPRN', 'morphemes': [['kâ', '@UNK@', 'ᴅᴇᴍ2.ᴅꞮЅᴛ', '@UNK@', 'stem']], 'word_gloss': 'which'}, {'token': 'x', 'wPOS': 'CONJ', 'morphemes': [['ä', '@UNK@', 'and', 'CONJ', 'stem']], 'word_gloss': 'and'}, {'token': 'dckta', 'wPOS': 'N', 'morphemes': [['dâkta', '@UNK@', 'doctor', 'N', 'stem']], 'word_gloss': 'doctor'}, {'token': 'ncwrngr', 'wPOS': '@UNK@', 'morphemes': [['ncwrngr', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'xmrle', 'wPOS': '@UNK@', 'morphemes': [['xmrle', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'twzq', 'wPOS': '@UNK@', 'morphemes': [['twz', '@UNK@', 'take', 'V', 'stem'], ['==ü', '@UNK@', '=2ᴍꞮɴI', 'Nom1', 'enclitic']], 'word_gloss': '@UNK@'}]}, {'text_title': 'zzz1st story ntu-boys-AW04', 'text_comment': 'No comment', 'line#': '6', 'free_transl': '@UNK@', 'orig_line': \"nrtqzpelr ngrwangr minyagu dakealele lcka nrepi nrlcde nzrpingr bz bam deyagwengr lc nqyagwengr kc medisin ngrde scba mz dwalc xpi olvzkc trpiba ngxelekrmkc mz'tqbrngrle xpikz mrlikc nrzpi nrlc li xkcmule delc x xmrngzrmqlangr ncblo ngzrmqlzngr ncblo trnginyu trnginyu dake lvae vzm bade ncblo mncnqwengr ncblo mncnqwengr\", 'words': [{'token': 'nrtqzpelr', 'wPOS': '@UNK@', 'morphemes': [['nrtqzpelr', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'ngrwangr', 'wPOS': '@UNK@', 'morphemes': [['ngrwangr', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'minyagu', 'wPOS': '@UNK@', 'morphemes': [['minyagu', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'dakealele', 'wPOS': '@UNK@', 'morphemes': [['dakealele', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'lcka', 'wPOS': '@UNK@', 'morphemes': [['lcka', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'nrepi', 'wPOS': '@UNK@', 'morphemes': [['nrepi', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'nrlcde', 'wPOS': '@UNK@', 'morphemes': [['nrlcde', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'nzrpingr', 'wPOS': '@UNK@', 'morphemes': [['nzrpingr', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'bz', 'wPOS': 'N', 'morphemes': [['bë', '@UNK@', 'boundary', 'N', 'stem']], 'word_gloss': 'boundary'}, {'token': 'bam', 'wPOS': 'A-D-P2', 'morphemes': [['ba-', '@UNK@', 'ᴅᴀᴛ', 'A-D-P2', 'stem'], ['==mü', '@UNK@', '=2ᴍꞮɴII', 'A-D-P2', 'enclitic']], 'word_gloss': 'to you'}, {'token': 'deyagwengr', 'wPOS': '@UNK@', 'morphemes': [['deyagwengr', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'lc', 'wPOS': 'Det', 'morphemes': [['lâ', '@UNK@', 'ᴅᴇᴍ1.ᴅɪѕᴛ', 'DEM', 'stem']], 'word_gloss': 'this'}, {'token': 'nqyagwengr', 'wPOS': '@UNK@', 'morphemes': [['nqyagwengr', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'kc', 'wPOS': 'RPRN', 'morphemes': [['kâ', '@UNK@', 'ᴅᴇᴍ2.ᴅꞮЅᴛ', '@UNK@', 'stem']], 'word_gloss': 'which'}, {'token': 'medisin', 'wPOS': '@UNK@', 'morphemes': [['medisin', '@UNK@', '@UNK@', '@UNK@', 'stem']], 'word_gloss': '@UNK@'}, {'token': 'ngrde', 'wPOS': 'Poss.pro', 'morphemes': [['ngö', '@UNK@', 'ɢᴇɴ1ᴀ', 'GEN', 'stem'], ['==de', '@UNK@', '=3ᴍꞮɴII', 'A-D-P2', 'enclitic']], 'word_gloss': '3min.poss'}, {'token': 'scba', 'wPOS': '@UNK@', 'morphemes': [['scba', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'mz', 'wPOS': 'PREP', 'morphemes': [['më', '@UNK@', 'ᴘʀᴇᴘ', 'PREP', 'stem']], 'word_gloss': 'PREP'}, {'token': 'dwalc', 'wPOS': '@UNK@', 'morphemes': [['dwalc', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'xpi', 'wPOS': '@UNK@', 'morphemes': [['xpi', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'olvzkc', 'wPOS': '@UNK@', 'morphemes': [['olvë', '@UNK@', 'wife', 'N', 'stem'], ['kâ', '@UNK@', 'ᴅᴇᴍ2.ᴅɪѕᴛ', 'DEM', 'stem']], 'word_gloss': '@UNK@'}, {'token': 'trpiba', 'wPOS': '@UNK@', 'morphemes': [['trpiba', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'ngxelekrmkc', 'wPOS': '@UNK@', 'morphemes': [['ngxelekrmkc', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': \"mz'tqbrngrle\", 'wPOS': '@UNK@', 'morphemes': [[\"mz'tqbrngrle\", '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'xpikz', 'wPOS': '@UNK@', 'morphemes': [['xpikz', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'mrlikc', 'wPOS': '@UNK@', 'morphemes': [['mrlikc', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'nrzpi', 'wPOS': '@UNK@', 'morphemes': [['nrzpi', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'nrlc', 'wPOS': 'N', 'morphemes': [['nölâ', '@UNK@', 'place', 'N', 'stem']], 'word_gloss': 'place'}, {'token': 'li', 'wPOS': 'NUM', 'morphemes': [['li', '@UNK@', 'two', 'NUM', 'stem']], 'word_gloss': 'two'}, {'token': 'xkcmule', 'wPOS': '@UNK@', 'morphemes': [['xkcmule', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'delc', 'wPOS': 'RPRN', 'morphemes': [['delâ', '@UNK@', 'this', 'RPRN', 'stem']], 'word_gloss': 'from that'}, {'token': 'x', 'wPOS': 'CONJ', 'morphemes': [['ä', '@UNK@', 'and', 'CONJ', 'stem']], 'word_gloss': 'and'}, {'token': 'xmrngzrmqlangr', 'wPOS': '@UNK@', 'morphemes': [['xmrngzrmqlangr', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'ncblo', 'wPOS': 'N', 'morphemes': [['nâblo', '@UNK@', 'man', 'N', 'stem']], 'word_gloss': 'man'}, {'token': 'ngzrmqlzngr', 'wPOS': '@UNK@', 'morphemes': [['ngzrmqlzngr', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'ncblo', 'wPOS': 'N', 'morphemes': [['nâblo', '@UNK@', 'man', 'N', 'stem']], 'word_gloss': 'man'}, {'token': 'trnginyu', 'wPOS': '@UNK@', 'morphemes': [['trnginyu', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'trnginyu', 'wPOS': '@UNK@', 'morphemes': [['trnginyu', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'dake', 'wPOS': '@UNK@', 'morphemes': [['dake', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'lvae', 'wPOS': '@UNK@', 'morphemes': [['lvae', '@UNK@', 'float', '<Not.Sure>', 'stem']], 'word_gloss': '@UNK@'}, {'token': 'vzm', 'wPOS': 'V', 'morphemes': [['vë', '@UNK@', 'go', 'V', 'stem'], ['-mü', '@UNK@', 'PᴅꞮƦ.HITHER', 'V:(PDIR)', 'suffix'], ['==', '@UNK@', '=3ᴍꞮɴIS', 'Nom1', 'enclitic']], 'word_gloss': 'come'}, {'token': 'bade', 'wPOS': 'A-D-P2', 'morphemes': [['ba-', '@UNK@', 'ᴅᴀᴛ', 'A-D-P2', 'stem'], ['==de', '@UNK@', '=3ᴍꞮɴII', 'A-D-P2', 'enclitic']], 'word_gloss': 'to him'}, {'token': 'ncblo', 'wPOS': 'N', 'morphemes': [['nâblo', '@UNK@', 'man', 'N', 'stem']], 'word_gloss': 'man'}, {'token': 'mncnqwengr', 'wPOS': '@UNK@', 'morphemes': [['mncnqwengr', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'ncblo', 'wPOS': 'N', 'morphemes': [['nâblo', '@UNK@', 'man', 'N', 'stem']], 'word_gloss': 'man'}, {'token': 'mncnqwengr', 'wPOS': '@UNK@', 'morphemes': [['mncnqwengr', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}]}]\n",
      "\n",
      "Sanity check unannotated data:\n",
      " []\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "LANGUAGE: tau\n",
      "Parts of speech found in corpus: {'nvp', 'pro', 'mod', 'dir', 'v', 'PUNCT', 'onom', 'post', 'adv', 'proform', 'nomprt', '@UNK@', 'verbprt', 'num', 'inter', 'cardnum', 'adj', 'interj', 'nprop', 'advlizer', 'dem', 'quant', 'imp', 'coordconn', 'n', 'DM'}\n",
      "\n",
      "All Tokens: 17587\n",
      "Lexemes, ignoring punctuation and digits: 14099\n",
      "Initial Extraction Sanity Check: [{'token': 'keey', 'wPOS': 'n', 'morphemes': [['keey', '@UNK@', 'village', 'n', 'stem']], 'word_gloss': 'village'}, {'token': 'tah', 'wPOS': 'post', 'morphemes': [['tah', '@UNK@', 'at:AR', 'post', 'stem']], 'word_gloss': 'at:AR'}, {'token': 'hihneeshyąą', 'wPOS': 'v', 'morphemes': [['h-', '@UNK@', '3PL.S.', 'v:Any', 'prefix'], ['nee-', '@UNK@', 'QUAL:DH.PFV:Ø.', 'Verb', 'prefix'], ['shyąą', '@UNK@', 'grow:PFV', 'v', 'stem']], 'word_gloss': '@UNK@'}, {'token': 'jah', 'wPOS': 'adv', 'morphemes': [['jah', '@UNK@', 'here', 'adv', 'stem']], 'word_gloss': 'here'}, {'token': 'dineh', 'wPOS': '@UNK@', 'morphemes': [['dineh', '@UNK@', 'person', 'n', 'stem']], 'word_gloss': '@UNK@'}, {'token': 'huuniign', 'wPOS': 'v', 'morphemes': [['huu-', '@UNK@', '3SG.S:QUAL:DH.PFV:Ø.', 'Verb', 'prefix'], ['niign', '@UNK@', 'grab:PFV:NOM', 'v', 'stem']], 'word_gloss': '@UNK@'}, {'token': \"u'aat\", 'wPOS': 'n', 'morphemes': [['u-', '@UNK@', '3SG.PSR.', 'Noun', 'prefix'], [\"'aat\", '@UNK@', 'wife', 'n', 'stem']], 'word_gloss': 'wife'}, {'token': \"ts'exeh\", 'wPOS': 'n', 'morphemes': [[\"ts'exeh\", '@UNK@', 'woman', 'n', 'stem']], 'word_gloss': 'woman'}, {'token': 'nadįhtįį', 'wPOS': '@UNK@', 'morphemes': [['nadįhtįį', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': '.', 'wPOS': 'PUNCT', 'morphemes': [['.', '@UNK@', '@UNK@', 'PUNCT', 'punct']], 'word_gloss': 'punct'}]\n",
      "Extraction done...\n",
      "\n",
      "Post filtering statistics:\n",
      "\tTotal words after filtering: 17587\n",
      "\tTotal training examples, after filtering for _surSeg 2398\n",
      "\tTotal punctuation and digits: 0\n",
      "\n",
      "\n",
      "Sanity check training examples:\n",
      " [{'text_title': \"Story of one woman; Ts'ehłegn ts'exeh naholndegn?   // UTOLVDN14Apr2602\", 'text_comment': 'No comment', 'line#': '158', 'free_transl': '@UNK@', 'orig_line': \"bill john mǫǫsi' .\", 'words': [{'token': 'bill', 'wPOS': '@UNK@', 'morphemes': [['bill', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': 'john', 'wPOS': '@UNK@', 'morphemes': [['john', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': \"mǫǫsi'\", 'wPOS': 'n', 'morphemes': [['u-', '@UNK@', '3SG.PSR.', 'Noun', 'prefix'], [\"ǫǫsi'\", '@UNK@', 'name', 'n', 'stem']], 'word_gloss': 'name'}, {'token': '.', 'wPOS': 'PUNCT', 'morphemes': [['.', '@UNK@', '@UNK@', 'PUNCT', 'punct']], 'word_gloss': 'punct'}]}, {'text_title': \"Story of one woman; Ts'ehłegn ts'exeh naholndegn?   // UTOLVDN14Apr2602\", 'text_comment': 'No comment', 'line#': '159', 'free_transl': '@UNK@', 'orig_line': \"łąy eh hatshyąą ay iin ch'ale hu'eh ihdaagn .\", 'words': [{'token': 'łąy', 'wPOS': 'adv', 'morphemes': [['łąy', '@UNK@', 'truly', 'adv', 'stem']], 'word_gloss': 'truly'}, {'token': 'eh', 'wPOS': 'coordconn', 'morphemes': [['eł', '@UNK@', 'and', 'coordconn', 'stem']], 'word_gloss': 'and'}, {'token': 'hatshyąą', 'wPOS': 'v', 'morphemes': [['hat-', '@UNK@', '3PL.S:AA.IPV:D.', 'Verb', 'prefix'], ['shyąą', '@UNK@', 'be.old:PFV', 'v', 'stem']], 'word_gloss': 'be.old:PFV'}, {'token': 'ay', 'wPOS': 'proform', 'morphemes': [['ay', '@UNK@', '3SG', 'proform', 'stem']], 'word_gloss': '3SG'}, {'token': 'iin', 'wPOS': 'nomprt', 'morphemes': [['iin', '@UNK@', 'PL', 'nomprt', 'stem']], 'word_gloss': 'pl'}, {'token': \"ch'ale\", 'wPOS': 'DM', 'morphemes': [[\"ch'a\", '@UNK@', 'FOC', 'DM', 'stem']], 'word_gloss': 'FOC'}, {'token': \"hu'eh\", 'wPOS': '@UNK@', 'morphemes': [['hu-', '@UNK@', '3PL.P.', 'Postposition', 'prefix'], ['eł', '@UNK@', 'with', 'post', 'stem']], 'word_gloss': '@UNK@'}, {'token': 'ihdaagn', 'wPOS': 'v', 'morphemes': [['ih-', '@UNK@', 'Ø.PFV:1SG.S:Ø.', 'v', 'prefix'], ['daagn', '@UNK@', 'stay:PFV:CUST:NOM', 'v', 'stem']], 'word_gloss': '1SG.S:ø.IPV:ø'}, {'token': '.', 'wPOS': 'PUNCT', 'morphemes': [['.', '@UNK@', '@UNK@', 'PUNCT', 'punct']], 'word_gloss': 'punct'}]}, {'text_title': \"Story of one woman; Ts'ehłegn ts'exeh naholndegn?   // UTOLVDN14Apr2602\", 'text_comment': 'No comment', 'line#': '160', 'free_transl': '@UNK@', 'orig_line': 'ay tl\\'aan t\\'axoh shiin nahut~tthän eh , \" hospital nts\\'ą̈\\' natįįdaąy ,\" < shihenih .>', 'words': [{'token': \"ay tl'aan\", 'wPOS': 'coordconn', 'morphemes': [[\"ay.tl'aan\", '@UNK@', 'AND.THEN', 'coordconn', 'phrase']], 'word_gloss': 'and then'}, {'token': \"t'axoh\", 'wPOS': 'adv', 'morphemes': [[\"t'axoh\", '@UNK@', 'finally', 'adv', 'stem']], 'word_gloss': 'finally'}, {'token': 'shiin', 'wPOS': 'n', 'morphemes': [['shiin', '@UNK@', 'summer', 'n', 'stem']], 'word_gloss': 'summer'}, {'token': 'nahut~tthän', 'wPOS': 'dir', 'morphemes': [['na-', '@UNK@', 'IT.', 'Verb', 'prefix'], ['hut-', '@UNK@', 'AR.S:DH.PFV:D.', 'Verb', 'prefix'], [\"tthän'\", '@UNK@', 'waterward:ALL', 'dir', 'stem']], 'word_gloss': 'waterward:ALL'}, {'token': 'eh', 'wPOS': 'coordconn', 'morphemes': [['eł', '@UNK@', 'and', 'coordconn', 'stem']], 'word_gloss': 'and'}, {'token': ',', 'wPOS': 'PUNCT', 'morphemes': [[',', '@UNK@', '@UNK@', 'PUNCT', 'punct']], 'word_gloss': 'punct'}, {'token': '\"', 'wPOS': 'PUNCT', 'morphemes': [['\"', '@UNK@', '@UNK@', 'PUNCT', 'punct']], 'word_gloss': 'punct'}, {'token': 'hospital', 'wPOS': '@UNK@', 'morphemes': [['hospital', '@UNK@', '@UNK@', '@UNK@', 'txt']], 'word_gloss': '@UNK@'}, {'token': \"nts'ą̈'\", 'wPOS': 'post', 'morphemes': [[\"nts'ą'\", '@UNK@', 'to', 'post', 'stem']], 'word_gloss': 'to'}, {'token': 'natįįdaąy', 'wPOS': 'v', 'morphemes': [['na-', '@UNK@', 'IT.', 'Verb', 'prefix'], ['tįį-', '@UNK@', 'INC:AA.IPV:2SG.S.', 'v', 'prefix'], ['daay', '@UNK@', 'D:SG.go:IPV:IMP', 'v', 'stem']], 'word_gloss': 'handle.AO:PFV'}, {'token': ',\"', 'wPOS': 'PUNCT', 'morphemes': [[',\"', '@UNK@', '@UNK@', 'PUNCT', 'punct']], 'word_gloss': 'punct'}, {'token': '<', 'wPOS': 'PUNCT', 'morphemes': [['<', '@UNK@', '@UNK@', 'PUNCT', 'punct']], 'word_gloss': 'punct'}, {'token': 'shihenih', 'wPOS': '@UNK@', 'morphemes': [['sh-', '@UNK@', '1SG.O.', 'Verb', 'prefix'], ['he-', '@UNK@', '3PL.S:Ø.IPV:Ø.', 'Verb', 'prefix'], ['nih', '@UNK@', 'say:IPV', 'v', 'stem']], 'word_gloss': '@UNK@'}, {'token': '.>', 'wPOS': 'PUNCT', 'morphemes': [['.>', '@UNK@', '@UNK@', 'PUNCT', 'punct']], 'word_gloss': 'punct'}]}, {'text_title': \"Story of one woman; Ts'ehłegn ts'exeh naholndegn?   // UTOLVDN14Apr2602\", 'text_comment': 'No comment', 'line#': '161', 'free_transl': '@UNK@', 'orig_line': \"ay ishyiit k'eh t'axoh .\", 'words': [{'token': 'ay', 'wPOS': 'coordconn', 'morphemes': [['ay', '@UNK@', 'and', 'coordconn', 'stem']], 'word_gloss': 'and'}, {'token': 'ishyiit', 'wPOS': 'adv', 'morphemes': [['ishyiit', '@UNK@', 'there', 'adv', 'stem']], 'word_gloss': 'there'}, {'token': \"k'eh\", 'wPOS': 'post', 'morphemes': [[\"k'eh\", '@UNK@', 'like', 'post', 'stem']], 'word_gloss': 'like'}, {'token': \"t'axoh\", 'wPOS': 'adv', 'morphemes': [[\"t'axoh\", '@UNK@', 'finally', 'adv', 'stem']], 'word_gloss': 'finally'}, {'token': '.', 'wPOS': 'PUNCT', 'morphemes': [['.', '@UNK@', '@UNK@', 'PUNCT', 'punct']], 'word_gloss': 'punct'}]}, {'text_title': \"Story of one woman; Ts'ehłegn ts'exeh naholndegn?   // UTOLVDN14Apr2602\", 'text_comment': 'No comment', 'line#': '162', 'free_transl': '@UNK@', 'orig_line': \"t'axoh !\", 'words': [{'token': \"t'axoh\", 'wPOS': 'adv', 'morphemes': [[\"t'axoh\", '@UNK@', 'finally', 'adv', 'stem']], 'word_gloss': 'finally'}, {'token': '!', 'wPOS': 'PUNCT', 'morphemes': [['!', '@UNK@', '@UNK@', 'PUNCT', 'punct']], 'word_gloss': 'punct'}]}]\n",
      "\n",
      "Sanity check unannotated data:\n",
      " []\n"
     ]
    }
   ],
   "source": [
    "#### NOTE: EDIT filtering() function above to suit your purposes!!! ####\n",
    "\n",
    "#### FOR POS FILTERING:\n",
    "### Current possible POS tags to select\n",
    "## lezgi pos tags: {'ordnum', 'Vnf', 'num', 'indfpro', 'nprop', 'emph', 'Vocpart', 'proform', 'multipnum', 'prep', 'adv', 'post', 'ptcp', 'pers', 'verbprt', 'coordconn', 'adj', 'v', 'conn', 'poss', 'pro', 'prt', 'det', 'dem', 'interj', 'msd', 'subordconn', 'Vf', 'cardnum', 'n', 'interrog', 'recp'}\n",
    "## Alas pos tags: {'num', 'n', 'refl', 'Aux', 'vt', 'cop', 'clf', 'adv', 'prt', 'Adj', 'cardnum', 'vi', 'stc', 'existmrkr', 'quant', 'relpro', 'ordnum', 'vd', 'distrnum', 'adj', 'Prep', 'nprop', 'interj', 'Conj', 'dem', 'v', 'pro'}\n",
    "## Upper Tanana Pos tags: {'dem', 'advlizer', 'nvp', 'nprop', 'inter', 'proform', 'imp', 'coordconn', 'v', '@@@', 'nomprt', 'verbprt', 'adv', 'adj', 'NUM', 'n', 'interj', 'pro', 'onom', 'PUNCT', 'cardnum', 'quant', 'mod', 'DM', 'dir', 'post'}\n",
    "## Bonggi POS tags: {'V.ACH.ABIL', 'V.ACL', 'CLF', 'V.ST1', 'INT.EXP.ST', 'Coordconj', 'PUNCT', 'INTNS', 'REFL.PRO', 'V.ISA.MRK.UV', 'V.ST.PER', 'PP', 'Adv.loc', 'V.CAUS.UV', 'N.CHAR.NMLZ', 'Prep', 'ADV.MAN', 'V.ACY.SE', 'N.Temp', 'QW', 'V.ISA', 'V.ST.POSS', 'MO.ACY.PATH', 'ADJ', 'V', 'V.ACH', 'N.ABSTR', 'INDEF.PRO', 'Rel', 'V.ST.DES', 'Mult.Num', 'V.ISA.UV', 'V.CAUS', 'PersName', '@@@', 'V.ST.POS', 'MOD', 'N.PROD', 'Interj', 'V.ABL.MOD', 'V.INSTRV', 'TNS', 'EX.ST', 'N.peg--an', 'ST.ATTR', 'AUX.UV', 'PERS.PRO', 'DEM.PRO', 'Det.PN', 'Subordconj', 'PEG-tsc.AV<N', 'Adv.temp', 'NP', 'V.ACY.C2', 'Adv.epis', 'NEG', 'Card.Num', 'MO.ACY.M', 'V.PET', 'N.Voc', 'V.ADVRS.ACH', 'Det', 'V.PLAC.ACY', 'ASP', 'V.DES.MOD', 'Adv.pace', 'N.p-.-an', 'Conn', 'CLS.MENS', 'PEG-tsc.UV<V', 'V.CAUS.AV', 'V.ST.POSS.denom', 'N.Prop', 'QUAN', 'V.ISA.AV', 'V.ST.EMO', 'Adv.freq', 'CLS.SORT', 'V.ST', 'NEG.PRO', 'N.DIMIN.redup', 'ADNOM.DEM', 'COND.ST', 'PRT', 'V.ST.COG', 'V.ACD.MOD', 'PEG-tsc.AV<V', 'V.ST2', 'peg-verb.temp.sub.cl', 'V.ACY.M', 'N', 'Ord.Num', 'V.ACY', 'Adv'}\n",
    "#SELECT_POS_TAGS = []\n",
    "\n",
    "#### TASKS: \n",
    "### All possible tasks: ['_canSeg', '_surSeg', '_gls', '_canSegGls', '_surSegGls', '_pos', '_wrdgls', '_infl']\n",
    "### gls = glossing only, seg = segmentation only,\n",
    "### can = canonical (underlying) morphemes, surf = surface morphs\n",
    "### SegGls = segmentation+glossing, pos = (word) POS tagging\n",
    "### infl = (re)inflection, affix glosses for words and POS tags\n",
    "DESIRED_TASKS = ['_surSeg'] \n",
    "\n",
    "#### LANGUAGES:\n",
    "LANGS = ['bdg','btz','cho','lez','ntu','tau'] # ['bdg','btz','cho','lez','ntu','tau'] \n",
    "\n",
    "####### RUN CODE: \n",
    "for lang in LANGS:\n",
    "    print('\\n\\nLANGUAGE:', lang)\n",
    "    for task in DESIRED_TASKS:\n",
    "        store = r\"../Research/MorphologyLRL/LLMinferring/\"+lang\n",
    "        to_extract = r'./flextexts/'+lang+'-all_txts.flextext'\n",
    "        main(store, to_extract, task, bysentence=True, useoriginalline=True, json=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
